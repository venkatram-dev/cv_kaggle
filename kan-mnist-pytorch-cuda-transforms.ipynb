{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-17T16:32:04.402647Z","iopub.execute_input":"2022-08-17T16:32:04.403333Z","iopub.status.idle":"2022-08-17T16:32:04.412290Z","shell.execute_reply.started":"2022-08-17T16:32:04.403296Z","shell.execute_reply":"2022-08-17T16:32:04.411250Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/Kannada-MNIST/sample_submission.csv\n/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\n/kaggle/input/Kannada-MNIST/train.csv\n/kaggle/input/Kannada-MNIST/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:06.210769Z","iopub.execute_input":"2022-08-17T16:32:06.212976Z","iopub.status.idle":"2022-08-17T16:32:08.951297Z","shell.execute_reply.started":"2022-08-17T16:32:06.212927Z","shell.execute_reply":"2022-08-17T16:32:08.949737Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchvision import transforms\n\n#my_tranforms = transforms.Compose ([transforms.ToTensor()])\nmy_tranforms = transforms.Compose ([ transforms.ToPILImage(), transforms.ToTensor()])\n\n#my_tranforms = transforms.Compose ([ transforms.ToPILImage()])\n\n#my_tranforms = transforms.Compose ([transforms.ToTensor(),transforms.Normalize((0.5, ), (0.5, ))])\n","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:10.957400Z","iopub.execute_input":"2022-08-17T16:32:10.957980Z","iopub.status.idle":"2022-08-17T16:32:11.192483Z","shell.execute_reply.started":"2022-08-17T16:32:10.957927Z","shell.execute_reply":"2022-08-17T16:32:11.191495Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\n\n\nclass kan_dataset(Dataset):\n    def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n        df = pd.read_csv(csv_file)\n        self.test_data = test_data\n        if self.test_data ==0:\n            self.y = df['label']\n            self.y = self.y.to_numpy()\n        else:\n            self.y = None\n        \n        self.x = df.iloc[:,1:]\n        \n        self.x = self.x.to_numpy().astype(np.uint8)\n        \n        #self.x = self.x.to_numpy().astype(float)\n        #self.x = self.x.to_numpy()\n        #self.x = self.x.reshape(self.x.shape[0],1,28,28)\n        \n        #numpy images have color channels last \n        self.x = self.x.reshape(self.x.shape[0],28,28,1)\n        \n        self.transform = transform\n        \n        #print ('self.x',self.x)\n        \n    def __len__(self):\n        return (len(self.x))\n    \n    def __getitem__(self, idx):\n        data = self.x[idx]\n        transformed_data = self.transform (data)\n        if self.test_data ==0:\n            label = self.y[idx]\n            return transformed_data, label\n        else:\n            return transformed_data\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:13.439856Z","iopub.execute_input":"2022-08-17T16:32:13.440869Z","iopub.status.idle":"2022-08-17T16:32:13.450099Z","shell.execute_reply.started":"2022-08-17T16:32:13.440822Z","shell.execute_reply":"2022-08-17T16:32:13.448943Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"kan_train_data = kan_dataset('/kaggle/input/Kannada-MNIST/train.csv',transform=my_tranforms)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:17.041531Z","iopub.execute_input":"2022-08-17T16:32:17.041970Z","iopub.status.idle":"2022-08-17T16:32:22.729279Z","shell.execute_reply.started":"2022-08-17T16:32:17.041930Z","shell.execute_reply":"2022-08-17T16:32:22.728275Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size =100\ntrain_data_loader = DataLoader(kan_train_data,batch_size=batch_size,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:22.731254Z","iopub.execute_input":"2022-08-17T16:32:22.731602Z","iopub.status.idle":"2022-08-17T16:32:22.736687Z","shell.execute_reply.started":"2022-08-17T16:32:22.731574Z","shell.execute_reply":"2022-08-17T16:32:22.735702Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for i,(data,labels) in enumerate(train_data_loader):\n    print ('data shape',data.size())\n    img1 = data[0].to(device)\n    print ('img1 shape',img1.size())\n    print ('img1 ',img1)\n    break\n    \n    #For this case using ([ transforms.ToPILImage(), transforms.ToTensor()]) results in same result as dividing numpy array by 255\n    # values match with https://www.kaggle.com/venkatram123/kan-mnist-pytorch\n    \n# data shape torch.Size([5, 1, 28, 28])\n# img1 shape torch.Size([1, 28, 28])\n# img1  tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.9176, 1.0000,\n#           1.0000, 0.5843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.9176, 1.0000,\n#           1.0000, 0.9059, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.6549, 0.9686, 1.0000,\n#           1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.1961, 0.6039, 1.0000, 1.0000, 0.6431,\n#           0.5255, 0.7216, 0.8667, 0.4745, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.1882, 0.6039, 0.9176, 0.6745, 0.6745, 0.1686,\n#           0.0000, 0.2824, 0.6745, 0.6745, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:26.816287Z","iopub.execute_input":"2022-08-17T16:32:26.816752Z","iopub.status.idle":"2022-08-17T16:32:30.357277Z","shell.execute_reply.started":"2022-08-17T16:32:26.816715Z","shell.execute_reply":"2022-08-17T16:32:30.356275Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"data shape torch.Size([100, 1, 28, 28])\nimg1 shape torch.Size([1, 28, 28])\nimg1  tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.6078, 0.7765, 0.7765, 0.8549, 0.8314, 0.2235, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1333, 0.6235,\n          0.6235, 0.9176, 1.0000, 0.6863, 0.3765, 0.2941, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.4745, 0.5882, 0.9647,\n          0.5569, 0.5255, 0.5255, 0.2627, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.2078, 0.6627, 0.8824, 0.6745, 0.6275,\n          0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.1373, 0.5922, 0.8235, 0.5294, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.7843, 0.3569, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.7843, 0.3569, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.7843, 0.8235, 0.3608, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.3333, 0.7961, 0.7882, 0.3686, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.3686, 0.7882, 0.7961, 0.3333, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.4980, 1.0000, 0.8431, 0.2549,\n          0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0980, 0.1255, 0.5608, 1.0000, 1.0000, 0.9294,\n          0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.7647, 0.9765, 0.9882, 1.0000, 1.0000, 0.9294,\n          0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.8235, 0.9608, 0.4706, 0.1765, 0.1765, 0.1765, 0.1608,\n          0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.4706, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.2118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.5098, 0.1333, 0.0000, 0.0000, 0.0784, 0.3490,\n          0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.7765, 0.9529, 0.5020, 0.2235, 0.2235, 0.3412, 0.7216,\n          0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.7843, 1.0000, 1.0000, 1.0000, 0.7843, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"#without any transforms\n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy()\n#         self.x = self.x.reshape(self.x.shape[0],1,28,28)\n        \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n        \n#         return data, label\n    \n    \n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n    \n# data shape torch.Size([5, 1, 28, 28])","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.335881Z","iopub.execute_input":"2022-08-17T01:34:21.337123Z","iopub.status.idle":"2022-08-17T01:34:21.341852Z","shell.execute_reply.started":"2022-08-17T01:34:21.337084Z","shell.execute_reply":"2022-08-17T01:34:21.340648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with \n\n# my_tranforms = transforms.Compose ([transforms.ToTensor()])\n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy()\n#         self.x = self.x.reshape(self.x.shape[0],1,28,28)\n\n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n    \n\n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n\n# data shape torch.Size([5, 28, 1, 28])\n\n# this is because ToTensor assumes that image is of Height,Width, Color_Channels and converts it to Color_Channels,Height,Width","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.34299Z","iopub.execute_input":"2022-08-17T01:34:21.343627Z","iopub.status.idle":"2022-08-17T01:34:21.35393Z","shell.execute_reply.started":"2022-08-17T01:34:21.34359Z","shell.execute_reply":"2022-08-17T01:34:21.352466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with transform to pil \n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy()\n#         self.x = self.x.reshape(self.x.shape[0],1,28,28)\n\n    \n    \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n    \n#     for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n\n#     ValueError: pic should not have > 4 channels. Got 28 channels.","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.357618Z","iopub.execute_input":"2022-08-17T01:34:21.358192Z","iopub.status.idle":"2022-08-17T01:34:21.370367Z","shell.execute_reply.started":"2022-08-17T01:34:21.35814Z","shell.execute_reply":"2022-08-17T01:34:21.369042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with just to tensor and different reshape \n\n# my_tranforms = transforms.Compose ([transforms.ToTensor()])\n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy()\n#         #self.x = self.x.reshape(self.x.shape[0],1,28,28)\n#         self.x = self.x.reshape(self.x.shape[0],28,28,1)\n        \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n    \n#     for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n\n#     data shape torch.Size([5, 1, 28, 28])\n","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.37209Z","iopub.execute_input":"2022-08-17T01:34:21.373078Z","iopub.status.idle":"2022-08-17T01:34:21.382544Z","shell.execute_reply.started":"2022-08-17T01:34:21.373039Z","shell.execute_reply":"2022-08-17T01:34:21.381076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with pil image transform\n\n# my_tranforms = transforms.Compose ([ transforms.ToPILImage(), transforms.ToTensor()])\n\n# TypeError: Input type int64 is not supported","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.384139Z","iopub.execute_input":"2022-08-17T01:34:21.385023Z","iopub.status.idle":"2022-08-17T01:34:21.398576Z","shell.execute_reply.started":"2022-08-17T01:34:21.384983Z","shell.execute_reply":"2022-08-17T01:34:21.396981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to fix above convert to unit8\n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy().astype(np.uint8)\n#         self.x = self.x.reshape(self.x.shape[0],28,28,1)\n        \n    \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n    \n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n    \n# data shape torch.Size([5, 1, 28, 28])","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.40033Z","iopub.execute_input":"2022-08-17T01:34:21.401192Z","iopub.status.idle":"2022-08-17T01:34:21.410926Z","shell.execute_reply.started":"2022-08-17T01:34:21.401146Z","shell.execute_reply":"2022-08-17T01:34:21.409888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# just to tensor does not do any normalize\n\n# sample output \n\n# img1  tensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21,\n#           234, 255, 255, 149,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21,\n#           234, 255, 255, 231, 148,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 167,\n#           247, 255, 255, 255, 191,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  50, 154, 255,\n#           255, 164, 134, 184, 221, 121,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 154, 234, 172,\n#           172,  43,   0,  72, 172, 172,   0,   0,   0,   0,   0,   0,   0,   0],\n               \n               ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.416172Z","iopub.execute_input":"2022-08-17T01:34:21.416803Z","iopub.status.idle":"2022-08-17T01:34:21.425397Z","shell.execute_reply.started":"2022-08-17T01:34:21.416764Z","shell.execute_reply":"2022-08-17T01:34:21.423999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use to_tensor and to_normalize,\n# does not do correctly\n\n\n# img1  tensor([[[ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  41., 467., 509., 509., 297.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  41., 467., 509., 509., 461., 295.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  79., 333., 493., 509., 509., 509., 381.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            99., 307., 509., 509., 327., 267., 367., 441., 241.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  95.,\n#           307., 467., 343., 343.,  85.,  -1., 143., 343., 343.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.42767Z","iopub.execute_input":"2022-08-17T01:34:21.428791Z","iopub.status.idle":"2022-08-17T01:34:21.442431Z","shell.execute_reply.started":"2022-08-17T01:34:21.428733Z","shell.execute_reply":"2022-08-17T01:34:21.44099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pil transform alone\n\n# my_tranforms = transforms.Compose ([ transforms.ToPILImage()])\n\n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     img1 = data[0]\n#     print ('img1 shape',img1.size())\n#     print ('img1 ',img1)\n#     break\n\n# TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.444131Z","iopub.execute_input":"2022-08-17T01:34:21.445393Z","iopub.status.idle":"2022-08-17T01:34:21.4595Z","shell.execute_reply.started":"2022-08-17T01:34:21.445348Z","shell.execute_reply":"2022-08-17T01:34:21.457852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using pil transform and to tensor is correct way to go\n\n# my_tranforms = transforms.Compose ([ transforms.ToPILImage(), transforms.ToTensor()])\n\n\n# class kan_dataset(Dataset):\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy().astype(np.uint8)\n        \n#         #self.x = self.x.to_numpy().astype(float)\n        \n#         #self.x = self.x.to_numpy()\n\n#         #self.x = self.x.reshape(self.x.shape[0],1,28,28)\n#         self.x = self.x.reshape(self.x.shape[0],28,28,1)\n        \n#         self.transform = transform\n        \n#         #print ('self.x',self.x)\n        \n#     def __len__(self):\n#         return (len(self.x))\n    \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n\n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     img1 = data[0]\n#     print ('img1 shape',img1.size())\n#     print ('img1 ',img1)\n#     break\n    \n    \n# data shape torch.Size([5, 1, 28, 28])\n# img1 shape torch.Size([1, 28, 28])\n# img1  tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.9176, 1.0000,\n#           1.0000, 0.5843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.9176, 1.0000,\n#           1.0000, 0.9059, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.6549, 0.9686, 1.0000,\n#           1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.1961, 0.6039, 1.0000, 1.0000, 0.6431,\n#           0.5255, 0.7216, 0.8667, 0.4745, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.1882, 0.6039, 0.9176, 0.6745, 0.6745, 0.1686,\n#           0.0000, 0.2824, 0.6745, 0.6745, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:34:21.461146Z","iopub.execute_input":"2022-08-17T01:34:21.462167Z","iopub.status.idle":"2022-08-17T01:34:21.476705Z","shell.execute_reply.started":"2022-08-17T01:34:21.462126Z","shell.execute_reply":"2022-08-17T01:34:21.475316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('img1 shape',img1.size())\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nnumpy_image = img1.cpu().numpy()\ntranspose_image = numpy_image.transpose(1,2,0)\nprint ('transpose_image shape',transpose_image.shape)\nplt.imshow(transpose_image)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:33:31.037166Z","iopub.execute_input":"2022-08-17T16:33:31.038261Z","iopub.status.idle":"2022-08-17T16:33:31.375949Z","shell.execute_reply.started":"2022-08-17T16:33:31.038185Z","shell.execute_reply":"2022-08-17T16:33:31.375009Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"img1 shape torch.Size([1, 28, 28])\ntranspose_image shape (28, 28, 1)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass kan_mnist_net(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.conv1= nn.Conv2d(1,32,5)\n        self.bc1 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2,2)\n        \n        self.conv2= nn.Conv2d(32,64,5)\n        self.bc2 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2)\n        \n        self.fc1 = nn.Linear(64 * 4*4, 1000)\n        self.bc3 = nn.BatchNorm1d(1000)\n        self.drop1 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(1000, 500)\n        self.bc4 = nn.BatchNorm1d(500)\n        self.fc3 = nn.Linear(500, 10)\n    \n    def forward(self,x):\n        conv1_x = F.relu(self.bc1(self.conv1(x)))\n        \n        pool1_x = self.pool1(conv1_x)\n        \n        conv2_x = F.relu(self.bc2(self.conv2(pool1_x)))\n        \n        pool2_x = self.pool2(conv2_x)\n        \n        #print ('pool2_x size', pool2_x.size())\n        \n        flatten_x = pool2_x.view(pool2_x.shape[0],-1)\n        \n        fc1_x = F.relu(self.bc3(self.fc1(flatten_x)))\n        drop1_x = self.drop1 (fc1_x)\n        fc2_x = F.relu(self.bc4(self.fc2(drop1_x)))\n        fc3_x = self.fc3(fc2_x)\n        \n        return fc3_x\n\nmodel = kan_mnist_net()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:33:39.785621Z","iopub.execute_input":"2022-08-17T16:33:39.786270Z","iopub.status.idle":"2022-08-17T16:33:39.830232Z","shell.execute_reply.started":"2022-08-17T16:33:39.786227Z","shell.execute_reply":"2022-08-17T16:33:39.828931Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"kan_mnist_net(\n  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n  (bc1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n  (bc2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=1024, out_features=1000, bias=True)\n  (bc3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (drop1): Dropout(p=0.5, inplace=False)\n  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n  (bc4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc3): Linear(in_features=500, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dat_iterator = iter(train_data_loader)\nsample_data = next(dat_iterator)\n\nimage = sample_data[0].to(device)\nlabel = sample_data[1].to(device)\nprint ('image size',image.size())\n\nprint ('label size',label.size())\nprint ('actual label ',label)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:33:43.050119Z","iopub.execute_input":"2022-08-17T16:33:43.051156Z","iopub.status.idle":"2022-08-17T16:33:43.077672Z","shell.execute_reply.started":"2022-08-17T16:33:43.051117Z","shell.execute_reply":"2022-08-17T16:33:43.076559Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"image size torch.Size([100, 1, 28, 28])\nlabel size torch.Size([100])\nactual label  tensor([2, 0, 0, 6, 1, 1, 4, 4, 1, 4, 1, 0, 5, 8, 6, 2, 9, 4, 0, 3, 2, 2, 3, 6,\n        9, 3, 0, 2, 3, 8, 0, 7, 2, 6, 4, 5, 4, 1, 8, 8, 9, 5, 8, 8, 2, 8, 2, 4,\n        7, 7, 0, 1, 6, 0, 7, 4, 4, 5, 4, 0, 0, 9, 2, 0, 9, 6, 2, 9, 1, 5, 5, 6,\n        7, 5, 7, 0, 3, 3, 2, 1, 5, 4, 6, 0, 4, 1, 5, 8, 6, 1, 7, 5, 4, 4, 5, 8,\n        2, 7, 7, 0], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"output = model(image)\nprint ('output size', output.size())\nprint ('output',output)\nmax_pred = output.argmax(axis=1)\nprint ('max_pred',max_pred)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:33:52.242936Z","iopub.execute_input":"2022-08-17T16:33:52.243312Z","iopub.status.idle":"2022-08-17T16:33:58.547572Z","shell.execute_reply.started":"2022-08-17T16:33:52.243281Z","shell.execute_reply":"2022-08-17T16:33:58.545429Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"output size torch.Size([100, 10])\noutput tensor([[-6.3146e-01,  4.8455e-01, -3.7723e-01,  4.2622e-01, -1.7321e-01,\n          1.8385e-01,  3.4801e-02, -2.3213e-01, -7.2301e-01,  5.9246e-01],\n        [ 2.2287e-01, -2.5007e-01,  2.5953e-02,  4.7398e-01,  2.4702e-01,\n         -1.1351e-01, -8.2178e-02,  1.2561e-01, -1.5894e-01,  3.9258e-01],\n        [-3.4546e-01,  2.8035e-01, -3.0741e-01,  4.1573e-01,  3.9974e-01,\n         -2.8484e-01,  3.0221e-01,  1.0377e-01,  3.5045e-01, -1.6852e-01],\n        [-5.2177e-01,  1.6949e-02,  3.8459e-01,  4.4130e-01, -2.0049e-01,\n         -2.8251e-01, -1.9552e-01,  4.4703e-02, -3.4025e-01,  6.1267e-01],\n        [ 6.6308e-01,  1.3916e-01,  7.4571e-01,  6.9279e-01,  1.1254e-01,\n         -2.7957e-01, -2.4860e-01, -1.6780e-02,  1.8713e-01, -1.1293e-01],\n        [-8.5286e-02, -1.6519e-01, -1.3409e-01,  4.1946e-01,  2.4170e-02,\n         -2.8650e-01, -3.9305e-01,  9.6851e-02, -4.0996e-01, -1.2180e-01],\n        [ 1.5091e-02,  3.6296e-01, -8.9666e-01,  5.4874e-01, -7.2208e-02,\n         -1.0991e+00, -8.8777e-01,  3.0202e-02, -8.6181e-01,  2.0584e-01],\n        [ 3.8675e-01,  5.1538e-01, -3.8203e-01,  5.6180e-01, -1.0001e-01,\n         -2.2681e-01, -5.2862e-01,  6.8267e-01, -9.8545e-01,  3.7786e-01],\n        [ 6.2843e-01,  1.6806e-01, -2.0134e-02,  6.1437e-01,  2.7461e-01,\n          2.1909e-01, -2.8618e-01, -2.7980e-01, -1.1849e+00, -1.7081e-01],\n        [ 2.2651e-01,  4.2718e-01, -4.5600e-01, -2.9874e-01, -2.3899e-01,\n         -5.6055e-01, -4.0673e-02,  1.4529e-01, -9.6136e-01, -1.2209e-01],\n        [ 6.3658e-02, -2.9849e-01,  1.2463e-01,  3.9259e-01,  3.4724e-01,\n          1.4077e-01, -3.0905e-01, -5.8695e-03,  1.0205e-01, -3.1316e-01],\n        [ 3.3869e-01, -4.7498e-01, -2.9171e-01,  1.9051e-01,  1.8596e-01,\n          7.1650e-02, -2.8856e-01,  9.6747e-01, -7.1533e-01, -2.5646e-01],\n        [ 2.8395e-01, -2.3469e-01,  6.1620e-01,  8.6628e-01, -1.9417e-02,\n         -4.3868e-01, -1.9043e-01,  1.7448e-01, -8.8117e-01,  9.8355e-02],\n        [-3.4970e-01, -1.0797e-01, -5.8858e-01, -1.2362e-01,  7.0057e-02,\n         -5.1643e-01, -3.2446e-01,  1.2058e-01, -4.0736e-01,  2.9518e-02],\n        [ 3.4881e-01,  1.2638e-01, -9.0726e-02,  7.8968e-01,  5.0026e-01,\n          2.1831e-01, -6.8248e-01,  6.9561e-01, -6.7482e-01,  7.8311e-01],\n        [ 9.2263e-02, -2.4307e-01, -1.5969e-01,  5.1005e-01,  4.3533e-01,\n         -3.1876e-01, -5.8926e-01, -3.2346e-01,  6.0729e-01, -1.8076e-01],\n        [-9.6965e-02, -1.9483e-01,  5.0357e-01,  6.4164e-01,  2.6787e-02,\n         -1.2050e-01, -5.1344e-01, -3.3012e-01, -2.3923e-01, -4.7263e-01],\n        [ 5.5364e-01,  6.7617e-02, -4.0469e-01,  1.0964e-01,  4.8949e-01,\n          3.5441e-01, -6.9263e-01, -5.7951e-01, -9.2466e-01,  7.0852e-02],\n        [ 2.6480e-01,  3.2626e-01, -5.7676e-02,  2.8821e-01, -7.3332e-01,\n         -8.2774e-01, -7.5837e-01, -4.0142e-01, -2.3684e-01,  4.3376e-01],\n        [ 2.4873e-03, -5.3994e-02, -3.7051e-01, -7.6003e-02, -4.4321e-01,\n         -3.7567e-01, -3.4857e-01, -3.6283e-01, -3.0929e-01,  1.5378e-01],\n        [-8.7952e-02, -6.5007e-01,  4.6326e-01,  4.8559e-01,  3.0498e-01,\n          4.8793e-02, -4.9131e-01,  3.5935e-01,  6.4857e-01, -2.9137e-01],\n        [ 5.6720e-02,  4.6745e-02, -3.4007e-01,  2.3995e-01, -4.0283e-01,\n         -2.2576e-01, -3.6930e-02, -2.2293e-01, -6.0036e-01,  3.4576e-01],\n        [ 6.5226e-01,  1.1751e-01,  9.4936e-02,  4.3960e-01, -1.5833e-01,\n         -9.3226e-01, -3.1239e-01, -1.6157e-01, -4.4914e-01, -1.4240e-01],\n        [-1.9369e-01,  4.0438e-01,  1.3883e-02,  1.7327e-02, -8.1137e-01,\n         -9.1892e-01,  1.2385e-02, -8.7927e-03, -2.0260e-01,  3.7741e-01],\n        [ 2.7884e-01,  4.1405e-02, -2.7922e-01,  7.4466e-01,  3.5641e-02,\n          6.7607e-02, -2.5658e-01, -2.1519e-01, -3.8953e-01,  2.3531e-01],\n        [ 4.2653e-01, -3.6534e-01, -7.6929e-02, -1.9308e-01,  1.4639e-01,\n         -2.5866e-01,  1.7920e-01,  6.5445e-02, -5.3093e-01, -4.8684e-02],\n        [-2.9563e-02, -6.0084e-03, -4.6778e-01,  3.6386e-01,  2.3448e-01,\n         -7.8198e-02, -4.8692e-01,  1.6107e-01, -7.6662e-01, -4.9498e-02],\n        [-2.4762e-01,  1.7173e-01, -4.8936e-01,  9.8828e-02, -3.3689e-01,\n         -3.4251e-01, -2.2066e-01, -1.4795e-01, -3.3718e-01, -2.4813e-01],\n        [ 1.1838e+00,  4.4741e-02, -3.0740e-02,  3.0471e-01,  2.9893e-01,\n          5.1585e-02, -6.1851e-02,  1.1408e-01, -8.6217e-01, -6.1420e-02],\n        [ 5.5926e-01, -1.1860e-01, -2.7777e-01,  5.5877e-02,  7.8093e-01,\n          1.6819e-01, -6.2772e-01,  4.5998e-01, -9.1304e-02, -2.4223e-01],\n        [ 1.4156e-01,  1.3142e-01, -2.7861e-01,  3.3039e-01,  2.5652e-01,\n          2.4680e-01, -6.5320e-01,  2.9604e-01, -4.9580e-02,  1.7589e-01],\n        [-1.7566e-02, -2.4846e-01,  2.6102e-01,  1.2183e-01,  2.8218e-01,\n          1.7758e-01, -4.5438e-01,  4.6995e-01,  1.7171e-02,  2.3467e-01],\n        [ 4.5824e-01, -2.0394e-01, -1.6406e-01,  3.7995e-01,  9.8183e-01,\n         -4.8854e-01, -1.4051e-01, -5.4539e-01, -1.0390e+00, -7.2137e-01],\n        [ 4.0944e-01, -2.9519e-01, -3.5265e-02,  5.2447e-01,  3.7273e-01,\n         -3.6913e-01, -3.9730e-01,  5.3120e-02, -2.0052e-01,  4.6678e-01],\n        [ 3.0655e-02,  7.7358e-02,  1.1348e-01,  3.8475e-01, -4.5617e-01,\n         -1.0992e-01, -3.0545e-01,  1.3905e-01, -7.4301e-01,  9.0091e-02],\n        [ 1.2391e-01, -1.8862e-01, -7.8940e-03, -1.7617e-01, -3.1365e-01,\n         -1.9127e-01, -2.9313e-01, -2.0776e-01, -7.6335e-02, -1.5741e-01],\n        [-1.5535e-01,  1.5930e-02, -9.0672e-02,  4.1238e-01,  1.8906e-01,\n         -2.4594e-01,  2.5898e-01,  3.9780e-01, -5.9720e-01,  2.9367e-01],\n        [ 2.8328e-02,  2.1951e-01, -6.2231e-01,  7.9455e-01, -3.8258e-02,\n         -1.7618e-02, -6.3727e-01, -4.4449e-01, -4.6436e-01,  1.4728e-01],\n        [ 2.4950e-01, -1.9131e-03,  2.3467e-01,  1.0791e+00,  5.6138e-02,\n         -5.0972e-01, -5.9298e-01, -3.6296e-02, -8.8665e-01, -1.1106e-01],\n        [ 3.4063e-01, -3.2751e-01,  4.6139e-01,  2.9224e-02, -6.4320e-01,\n         -1.8136e-01,  1.3726e-01,  5.9592e-01, -6.7113e-01, -4.4270e-01],\n        [ 3.8119e-01, -6.7426e-02, -2.0854e-01,  2.9121e-01, -7.8134e-02,\n          5.9907e-02, -2.3292e-01, -4.7536e-01, -2.1960e-01, -4.8792e-01],\n        [ 1.0714e-01,  2.9628e-01, -7.2189e-01,  3.6993e-01,  2.9372e-01,\n          7.1540e-02, -1.5942e-01,  7.9491e-01, -2.4126e-01,  7.9326e-02],\n        [-3.1540e-03, -3.1507e-01, -1.8248e-01,  4.7141e-02, -3.0026e-01,\n         -1.1158e-01, -6.8048e-02,  2.4707e-01, -7.8163e-01,  4.3996e-01],\n        [ 4.9069e-02, -6.6543e-01, -8.2759e-02, -9.5782e-02, -1.7182e-01,\n         -6.4209e-01, -5.2408e-01, -2.6425e-01, -1.2549e-02,  5.5902e-01],\n        [ 1.5471e-03,  5.3351e-02, -3.1067e-01,  9.7889e-01, -8.0681e-01,\n         -7.7319e-02, -7.2486e-01, -2.9832e-01, -6.2225e-01, -7.0393e-01],\n        [-3.0078e-02, -5.5379e-01, -6.7516e-01, -2.2952e-01,  2.9795e-01,\n         -6.5477e-01, -6.1152e-02,  1.4633e-01, -4.0467e-01,  3.2712e-01],\n        [ 1.0419e-01, -2.2365e-01,  8.8968e-02,  7.5724e-01,  5.5415e-01,\n         -6.7884e-01, -4.8459e-01,  1.3006e-01, -1.5261e-01, -2.2216e-01],\n        [ 4.4403e-01,  1.0871e-01,  1.1796e-01,  2.1755e-02, -1.4387e-01,\n         -4.3747e-01, -5.7540e-01,  9.8636e-02, -2.7302e-01, -2.7947e-01],\n        [-2.3746e-01,  2.0653e-01, -2.7901e-01, -5.4397e-01,  6.9267e-01,\n         -2.1003e-01,  2.6658e-02, -2.5123e-01,  4.5149e-01, -1.8312e-01],\n        [-3.2209e-02, -1.0822e-01, -3.1698e-01,  7.9898e-01, -2.7325e-01,\n         -2.5570e-01, -9.1781e-01, -3.3727e-02, -5.9870e-01,  1.7698e-02],\n        [-6.3221e-02, -1.9273e-01, -4.3154e-01,  2.7253e-01,  9.8261e-02,\n         -1.6563e-01, -2.3031e-01,  6.8787e-01, -8.1592e-01, -1.6463e-01],\n        [ 2.7764e-02,  2.7175e-02,  2.5824e-01,  1.3552e-01, -8.8069e-02,\n         -4.6508e-01,  8.5825e-02,  4.5522e-02, -9.0926e-01,  3.2576e-01],\n        [ 7.5814e-01,  1.5192e-01, -3.3990e-01,  1.2638e-01, -3.2171e-01,\n         -7.5237e-01, -3.7322e-01,  1.5483e-01, -3.2718e-01, -3.1619e-01],\n        [ 3.4702e-01, -3.1087e-03, -1.2845e-01, -2.5370e-01, -7.8740e-01,\n         -7.2535e-02, -5.4248e-01, -3.0073e-02, -5.2179e-02,  7.9390e-01],\n        [ 2.6552e-01,  1.5372e-01, -2.8823e-01,  2.1647e-01, -3.9541e-01,\n         -1.5623e-01, -1.7170e-01, -5.6671e-02, -4.8422e-01,  4.7135e-01],\n        [ 2.4340e-01, -3.3124e-02, -8.9160e-01,  3.9865e-02,  1.5672e-02,\n         -2.9744e-01, -7.8822e-01, -5.1228e-01, -9.0185e-01,  3.9584e-03],\n        [-7.1191e-03,  1.3147e-01, -3.4508e-01,  6.8779e-02,  2.7938e-01,\n         -5.3899e-01, -5.9903e-01, -2.5971e-01, -2.2702e-01,  3.7326e-01],\n        [ 8.7543e-02, -5.4824e-01,  6.5356e-01,  1.9315e-01,  3.0113e-01,\n         -4.7768e-01, -5.1285e-01, -1.0973e-01, -1.8176e-01,  1.8667e-01],\n        [ 3.7843e-02,  3.1736e-01,  9.8543e-02,  1.1192e+00,  5.9592e-02,\n         -2.1061e-01, -5.8470e-01,  1.1822e-01, -5.0306e-01,  3.5234e-01],\n        [ 5.8883e-01, -6.3320e-02, -7.0949e-02,  5.3281e-01, -2.9319e-01,\n         -1.3990e-01, -3.0329e-01, -5.0298e-02, -1.3628e-01,  3.9135e-01],\n        [ 3.9703e-01, -2.7841e-01, -5.2846e-01, -2.1033e-01, -5.1592e-01,\n          1.3534e-01, -6.1070e-01,  8.7690e-02,  3.9510e-02,  1.5218e-01],\n        [-2.4421e-01,  5.7109e-02,  8.0729e-01,  7.6280e-01, -1.3677e-01,\n         -6.6075e-01, -6.8573e-01, -1.7058e-01, -5.6073e-01,  3.5395e-01],\n        [ 7.1772e-01, -5.2142e-01, -4.4242e-01,  6.4788e-01, -4.7724e-01,\n         -4.2227e-02, -7.3817e-01,  8.1172e-02,  9.7508e-02, -1.4254e-01],\n        [ 1.2849e-01,  1.6059e-01, -3.4112e-01,  2.9544e-02, -3.8315e-01,\n          1.2048e-02, -5.6877e-01,  8.5380e-02, -4.6386e-01,  2.4026e-01],\n        [-2.7452e-03, -2.8100e-01, -3.3767e-01,  4.5503e-01, -1.9237e-01,\n         -8.3750e-01, -1.6825e-01, -1.4462e-01, -2.7223e-01,  8.1820e-01],\n        [ 1.7274e-01,  4.7886e-01, -2.6985e-01, -1.0138e-01, -4.0496e-01,\n         -3.9548e-01, -6.4718e-01, -7.6684e-02,  3.0339e-01,  5.1593e-02],\n        [-8.8681e-01,  1.4915e-01, -6.3324e-01,  6.1473e-01,  2.5523e-01,\n         -5.4148e-02, -7.6460e-01, -3.9473e-01, -3.0550e-01,  3.4232e-01],\n        [ 1.4740e-01,  6.2212e-02, -1.0293e-01,  6.1233e-01, -8.1632e-02,\n         -2.3338e-01, -7.3565e-01,  1.8402e-01, -1.8933e-01,  2.7836e-01],\n        [-2.7943e-01, -3.6200e-01, -1.2307e-01,  5.3446e-01, -2.9416e-01,\n         -3.8744e-01, -3.7293e-01,  2.2785e-01, -7.9426e-01,  2.7585e-01],\n        [ 5.0951e-01,  1.2406e-01, -1.2134e-01,  4.5685e-01,  1.9001e-01,\n         -2.1006e-01, -1.6872e-02, -2.6345e-01, -7.2822e-01, -1.1328e-01],\n        [ 1.6264e-01,  4.0828e-01, -2.5248e-01,  1.3464e-01, -2.8207e-01,\n         -1.0933e-01, -7.4981e-01,  2.7644e-02, -1.7976e-01, -2.2826e-01],\n        [ 4.7753e-01,  7.8211e-01, -1.7125e-03,  8.5860e-01,  5.9706e-01,\n         -7.1410e-01, -1.1406e-02,  6.1786e-01, -6.2613e-01,  3.7173e-01],\n        [ 3.7138e-01, -2.6468e-01,  9.3495e-01,  3.7241e-01, -6.0634e-01,\n         -9.5687e-01, -8.3134e-01,  3.4242e-01, -1.8821e-01,  5.5129e-01],\n        [ 2.5914e-01, -8.4849e-02, -8.2382e-01, -1.3719e-01, -1.4767e-01,\n         -3.1712e-01,  1.4419e-02,  5.6774e-03, -6.0846e-01, -1.0366e-01],\n        [-1.1381e-01,  1.0182e-01, -2.8954e-01,  4.0486e-01,  1.8149e-01,\n          2.9794e-01, -1.0814e+00, -4.2197e-01, -4.9985e-01,  2.5177e-01],\n        [ 2.8462e-02, -2.7979e-01, -2.2490e-02,  3.5009e-01,  3.5304e-01,\n          9.5917e-02, -1.7855e-01, -4.8296e-02, -3.6375e-01,  9.4480e-02],\n        [-8.5152e-01, -3.6808e-01, -1.6223e-01,  1.3270e-01, -3.8269e-01,\n         -3.7640e-01, -2.0596e-01,  1.8923e-02, -4.2637e-01,  4.8510e-01],\n        [ 1.5219e-01, -2.7509e-01,  1.7763e-02,  8.3049e-02, -4.2873e-01,\n         -6.7170e-01, -5.1458e-01, -2.0384e-01, -1.1816e+00,  7.3024e-01],\n        [-2.6211e-01,  2.8447e-02, -4.9618e-01,  4.9040e-01,  2.1581e-01,\n          5.7708e-02, -7.8920e-01, -3.3162e-01, -1.9982e-01,  4.7686e-01],\n        [ 4.4154e-01,  1.2464e-01,  5.9759e-02,  8.2633e-01,  1.5878e-01,\n         -6.0423e-01, -1.6415e-01,  1.3424e-01, -5.1858e-01, -4.1839e-02],\n        [ 8.0476e-02,  7.7235e-02, -1.0641e+00,  5.4262e-01,  3.3987e-03,\n         -8.8344e-03, -3.8835e-01,  5.6912e-01, -8.1829e-01, -1.7194e-01],\n        [ 4.4621e-01, -2.8395e-01, -4.6738e-01,  5.5164e-02, -7.1661e-02,\n         -4.3928e-01, -3.8374e-01, -8.3610e-02, -5.1197e-01,  2.0603e-01],\n        [ 2.9653e-01,  7.6945e-01,  4.2435e-01, -3.3034e-01, -1.4347e-01,\n         -4.4373e-01, -4.9088e-01,  2.3874e-01, -3.9847e-02,  1.2607e+00],\n        [ 1.8581e-01, -4.1561e-01, -5.7048e-01, -3.9593e-01, -5.9081e-03,\n         -3.1922e-01,  5.2722e-02, -4.5309e-01, -8.1271e-01, -2.5275e-01],\n        [ 4.8398e-01,  4.3116e-01, -1.2819e-01,  2.1679e-01,  1.1904e-01,\n         -9.9751e-02, -5.1351e-01, -3.9591e-02, -6.6925e-01,  1.3919e-01],\n        [ 1.3701e-01, -1.6748e-01, -2.0644e-01,  3.6140e-01,  1.6162e-01,\n         -1.1501e-01, -6.2743e-01, -9.6100e-02, -8.2845e-02, -3.6027e-01],\n        [ 1.8227e-03, -8.1364e-01, -2.2066e-01, -3.1945e-01, -2.2245e-01,\n          1.3775e-02, -9.0216e-02, -1.0472e-01, -1.0833e+00, -2.0708e-01],\n        [-1.9085e-01, -1.9466e-01,  2.6878e-01, -4.6641e-01,  1.3363e-01,\n          2.7443e-01, -3.0123e-01,  1.9843e-01, -4.4967e-01,  4.5428e-01],\n        [-1.6810e-01, -1.9815e-01,  1.0390e-01,  2.0270e-01, -5.1559e-02,\n         -7.0782e-01, -6.1018e-01,  5.4768e-02, -6.0441e-01, -1.1711e-01],\n        [ 5.4858e-01, -1.1797e-02, -2.1744e-01,  8.7313e-01,  3.1059e-02,\n          2.0405e-01, -4.2387e-01,  3.6480e-01, -4.4879e-01, -1.2981e-01],\n        [ 3.9525e-01, -2.9867e-01, -4.0415e-01, -6.6322e-02, -1.2226e-01,\n         -1.1038e+00, -8.5358e-01, -1.5535e-01, -6.6357e-01, -1.6821e-02],\n        [-7.0871e-01, -1.7896e-03, -4.1256e-01,  1.7728e-01,  2.0583e-02,\n          4.5990e-01, -1.5260e-01,  1.9146e-01, -1.5221e-01,  6.7294e-02],\n        [ 3.8828e-01, -4.0296e-01, -1.9886e-01,  3.2764e-01, -1.7934e-01,\n         -2.5740e-01, -5.5738e-01,  3.2248e-01, -5.7655e-01, -3.2213e-01],\n        [ 3.0918e-02,  8.1150e-02, -2.3172e-01,  6.2803e-01, -5.0564e-01,\n          6.1216e-01, -7.2440e-01, -3.3440e-01, -6.1730e-01, -1.5329e-01],\n        [-9.2718e-02, -8.7772e-02, -8.4720e-02,  1.3490e-01, -9.4198e-01,\n          2.8936e-01, -9.8950e-02, -2.0547e-01, -6.1463e-01, -5.8057e-01],\n        [ 6.7336e-01,  5.0363e-01, -9.5125e-02,  6.5522e-01,  1.2529e-01,\n         -3.9941e-01,  7.7531e-02,  5.0900e-01, -8.4055e-01,  3.5790e-01],\n        [-1.1187e-01,  2.1710e-01,  6.0839e-01,  4.4471e-01, -1.6763e-01,\n          3.7740e-01, -3.2109e-01,  1.1578e-01, -8.3288e-01,  3.0710e-01],\n        [ 7.7246e-01,  1.5822e+00, -6.6054e-01, -1.4000e-01, -4.9388e-01,\n         -5.7052e-02, -6.6938e-01, -6.8766e-01,  8.5775e-02,  4.6643e-01],\n        [ 9.7504e-01,  2.8357e-01,  4.6170e-01, -2.2094e-01, -3.7915e-01,\n         -5.0184e-01, -1.9798e-01,  2.5681e-01, -4.6984e-01,  1.9390e-01],\n        [ 9.1779e-02, -1.9619e-01, -1.5245e-01,  2.4470e-01,  3.9973e-01,\n          6.5649e-02, -1.2767e+00, -2.9194e-03, -2.6356e-01,  4.5351e-01]],\n       device='cuda:0', grad_fn=<AddmmBackward0>)\nmax_pred tensor([9, 3, 3, 9, 2, 3, 3, 7, 0, 1, 3, 7, 3, 7, 3, 8, 3, 0, 9, 9, 8, 9, 0, 1,\n        3, 0, 3, 1, 0, 4, 3, 7, 4, 3, 3, 0, 3, 3, 3, 7, 0, 7, 9, 9, 3, 9, 3, 0,\n        4, 3, 7, 9, 0, 9, 9, 0, 9, 2, 3, 0, 0, 2, 0, 9, 9, 1, 3, 3, 3, 0, 1, 3,\n        2, 0, 3, 4, 9, 9, 3, 3, 7, 0, 9, 0, 0, 3, 5, 9, 3, 3, 0, 5, 0, 3, 5, 0,\n        2, 1, 0, 9], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"model.parameters","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:34:09.005859Z","iopub.execute_input":"2022-08-17T16:34:09.006235Z","iopub.status.idle":"2022-08-17T16:34:09.013956Z","shell.execute_reply.started":"2022-08-17T16:34:09.006186Z","shell.execute_reply":"2022-08-17T16:34:09.012917Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<bound method Module.parameters of kan_mnist_net(\n  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n  (bc1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n  (bc2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=1024, out_features=1000, bias=True)\n  (bc3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (drop1): Dropout(p=0.5, inplace=False)\n  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n  (bc4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc3): Linear(in_features=500, out_features=10, bias=True)\n)>"},"metadata":{}}]},{"cell_type":"code","source":"import time\nstart = time.time()\nprint ('start',start)\n\n\nmodel = kan_mnist_net()\nmodel.to(device)\n\n#criterion = nn.CrossEntropyLoss()\n#below does not seem needed as since input is cuda, loss should be taken care already\ncriterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters(),lr=0.001)\n#using params=model.parameters() is very important\n#below did not cause convergence\n#optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n\nmodel.train()\n\nepochs = 50\n\nfor e in range(epochs):\n    \n    running_loss = 0\n    cnt = 0\n    \n    for i, data in enumerate(train_data_loader):\n        cnt+=1 \n        \n        image =data[0].to(device)\n        label = data[1].to(device)\n          \n        \n        #image = image.type(torch.FloatTensor)\n        \n        output = model(image)\n        \n        optimizer.zero_grad()\n        \n        loss = criterion(output,label)\n    \n        loss.backward()\n        \n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        if cnt%100 == 99:\n            print (f\"epoch {e} , i {i}, running_loss {running_loss}\")\n            running_loss = 0\n            \nend = time.time()\nprint ('end',end)\nprint('time taken',end - start)\nprint('time taken minutes',(end - start)/60)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:39:07.864182Z","iopub.execute_input":"2022-08-17T16:39:07.864729Z","iopub.status.idle":"2022-08-17T16:39:54.248066Z","shell.execute_reply.started":"2022-08-17T16:39:07.864687Z","shell.execute_reply":"2022-08-17T16:39:54.246284Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"start 1660754347.8819711\nepoch 0 , i 98, running_loss 18.98615239560604\nepoch 0 , i 198, running_loss 5.643915937282145\nepoch 0 , i 298, running_loss 5.1435641860589385\nepoch 0 , i 398, running_loss 4.160940175876021\nepoch 0 , i 498, running_loss 4.437479008221999\nepoch 0 , i 598, running_loss 3.8387009871657938\nepoch 1 , i 98, running_loss 2.9066844552289695\nepoch 1 , i 198, running_loss 2.835520467720926\nepoch 1 , i 298, running_loss 2.3674852536059916\nepoch 1 , i 398, running_loss 2.497236017487012\nepoch 1 , i 498, running_loss 2.978710552677512\nepoch 1 , i 598, running_loss 2.5936342724598944\nepoch 2 , i 98, running_loss 1.4497908710618503\nepoch 2 , i 198, running_loss 1.9485924853943288\nepoch 2 , i 298, running_loss 1.9345113537856378\nepoch 2 , i 398, running_loss 1.8602716306922957\nepoch 2 , i 498, running_loss 2.3593342261156067\nepoch 2 , i 598, running_loss 2.155788365926128\nepoch 3 , i 98, running_loss 1.739651290787151\nepoch 3 , i 198, running_loss 1.1582684142631479\nepoch 3 , i 298, running_loss 1.7560572470538318\nepoch 3 , i 398, running_loss 1.6021614560158923\nepoch 3 , i 498, running_loss 1.9479076358256862\nepoch 3 , i 598, running_loss 1.9137993936892599\nepoch 4 , i 98, running_loss 1.4711558356357273\nepoch 4 , i 198, running_loss 1.10505092117819\nepoch 4 , i 298, running_loss 1.2747104563895846\nepoch 4 , i 398, running_loss 1.210116086906055\nepoch 4 , i 498, running_loss 1.1131285076553468\nepoch 4 , i 598, running_loss 1.7417549011297524\nend 1660754394.243999\ntime taken 46.36202788352966\ntime taken minutes 0.7727004647254944\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction on test dataset","metadata":{}},{"cell_type":"code","source":"kan_test_data = kan_dataset('/kaggle/input/Kannada-MNIST/test.csv',transform=my_tranforms,test_data=1)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:53:11.156645Z","iopub.execute_input":"2022-08-17T16:53:11.156998Z","iopub.status.idle":"2022-08-17T16:53:11.503547Z","shell.execute_reply.started":"2022-08-17T16:53:11.156968Z","shell.execute_reply":"2022-08-17T16:53:11.502573Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nbatch_size= 100\ntest_data_loader = DataLoader(kan_test_data,batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:53:15.200010Z","iopub.execute_input":"2022-08-17T16:53:15.200576Z","iopub.status.idle":"2022-08-17T16:53:15.209145Z","shell.execute_reply.started":"2022-08-17T16:53:15.200535Z","shell.execute_reply":"2022-08-17T16:53:15.207809Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for i,data in enumerate(test_data_loader):\n    print ('data shape',data.size())\n    img1 = data[0].to(device)\n    print ('img1 shape',img1.size())\n    #print ('img1 ',img1)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:53:19.354350Z","iopub.execute_input":"2022-08-17T16:53:19.354949Z","iopub.status.idle":"2022-08-17T16:53:19.377469Z","shell.execute_reply.started":"2022-08-17T16:53:19.354916Z","shell.execute_reply":"2022-08-17T16:53:19.376378Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"data shape torch.Size([100, 1, 28, 28])\nimg1 shape torch.Size([1, 28, 28])\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions_tensor = torch.IntTensor().cuda()\n#predictions_tensor.cuda()\nprint ('predictions_tensor',predictions_tensor)\n\nwith torch.no_grad():\n    \n    for i,data in enumerate(test_data_loader):\n        \n        image= data.to(device)\n        test_out = model(image)\n        max_pred = test_out.argmax(axis=1)\n        print ((max_pred))\n        \n              \n        predictions_tensor = torch.cat((predictions_tensor,max_pred))    \n\nprint ('predictions_tensor size',predictions_tensor.size())\n#print ('predictions_tensor ',predictions_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:56:33.303163Z","iopub.execute_input":"2022-08-17T16:56:33.304469Z","iopub.status.idle":"2022-08-17T16:56:33.951908Z","shell.execute_reply.started":"2022-08-17T16:56:33.304369Z","shell.execute_reply":"2022-08-17T16:56:33.950987Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"predictions_tensor tensor([], device='cuda:0', dtype=torch.int32)\ntensor([3, 0, 2, 6, 7, 7, 1, 9, 3, 4, 8, 8, 1, 7, 8, 1, 5, 1, 5, 9, 3, 7, 6, 0,\n        2, 0, 8, 7, 0, 0, 8, 9, 2, 3, 2, 4, 6, 0, 7, 8, 3, 9, 4, 4, 5, 5, 7, 8,\n        7, 4, 3, 1, 9, 4, 5, 7, 1, 1, 6, 4, 6, 1, 2, 6, 1, 9, 1, 4, 9, 8, 4, 3,\n        7, 8, 5, 4, 1, 6, 1, 0, 3, 3, 4, 7, 3, 6, 3, 2, 2, 4, 2, 8, 7, 5, 7, 9,\n        7, 5, 7, 2], device='cuda:0')\ntensor([5, 2, 7, 9, 3, 9, 5, 7, 3, 9, 7, 3, 4, 6, 6, 2, 1, 6, 0, 7, 7, 1, 5, 4,\n        5, 2, 1, 2, 6, 0, 3, 9, 1, 5, 9, 6, 8, 1, 6, 4, 0, 9, 3, 9, 8, 1, 8, 6,\n        5, 0, 8, 6, 6, 0, 8, 1, 7, 8, 2, 5, 0, 8, 1, 0, 3, 1, 2, 6, 2, 2, 8, 9,\n        9, 3, 2, 5, 7, 4, 0, 6, 1, 2, 8, 7, 3, 8, 7, 8, 1, 9, 5, 2, 7, 6, 8, 2,\n        6, 5, 9, 1], device='cuda:0')\ntensor([9, 1, 3, 4, 4, 9, 7, 9, 0, 3, 0, 5, 1, 6, 2, 9, 0, 9, 0, 0, 5, 7, 4, 9,\n        2, 1, 2, 0, 3, 0, 3, 0, 9, 2, 0, 2, 6, 9, 4, 2, 4, 9, 9, 8, 5, 2, 2, 3,\n        7, 5, 3, 4, 5, 3, 7, 2, 5, 5, 4, 6, 8, 4, 1, 4, 8, 6, 1, 5, 2, 6, 6, 2,\n        4, 8, 4, 9, 3, 1, 6, 1, 4, 0, 9, 9, 5, 2, 6, 3, 0, 9, 7, 1, 7, 7, 2, 7,\n        4, 0, 8, 0], device='cuda:0')\ntensor([8, 3, 2, 3, 8, 9, 4, 3, 4, 1, 1, 3, 0, 3, 3, 8, 8, 2, 4, 7, 9, 4, 9, 4,\n        1, 7, 8, 2, 1, 7, 0, 7, 5, 9, 6, 9, 9, 1, 5, 8, 7, 5, 0, 0, 2, 3, 4, 7,\n        5, 9, 1, 1, 0, 1, 7, 5, 2, 8, 5, 2, 2, 0, 3, 8, 8, 5, 5, 8, 2, 3, 2, 2,\n        1, 3, 4, 7, 7, 0, 1, 2, 5, 3, 6, 2, 6, 6, 5, 9, 4, 4, 3, 8, 3, 8, 0, 6,\n        8, 3, 8, 4], device='cuda:0')\ntensor([9, 7, 0, 5, 7, 3, 8, 6, 9, 7, 5, 0, 8, 7, 9, 3, 5, 8, 3, 5, 7, 4, 1, 1,\n        7, 1, 6, 0, 3, 7, 8, 9, 9, 7, 9, 9, 3, 6, 0, 2, 9, 9, 4, 2, 8, 3, 8, 1,\n        3, 7, 8, 6, 9, 6, 8, 2, 6, 1, 9, 2, 1, 8, 6, 1, 0, 3, 1, 2, 1, 2, 6, 5,\n        3, 7, 9, 3, 4, 0, 0, 5, 1, 3, 0, 2, 8, 8, 1, 0, 2, 4, 3, 7, 4, 1, 7, 1,\n        6, 2, 0, 6], device='cuda:0')\ntensor([3, 5, 4, 7, 9, 2, 2, 4, 7, 7, 6, 8, 0, 3, 1, 4, 4, 1, 2, 3, 2, 7, 1, 2,\n        8, 9, 2, 3, 8, 9, 9, 3, 4, 8, 4, 1, 1, 3, 0, 5, 8, 1, 5, 9, 2, 1, 6, 6,\n        8, 9, 5, 7, 4, 7, 6, 2, 7, 7, 7, 4, 0, 2, 3, 0, 6, 1, 0, 7, 3, 3, 8, 6,\n        1, 0, 0, 7, 7, 7, 3, 8, 1, 9, 5, 8, 4, 1, 2, 5, 7, 7, 5, 4, 9, 2, 7, 5,\n        4, 6, 5, 7], device='cuda:0')\ntensor([0, 8, 0, 6, 0, 0, 1, 9, 9, 8, 2, 1, 8, 4, 0, 2, 0, 1, 8, 2, 1, 9, 9, 6,\n        3, 0, 7, 5, 8, 4, 2, 7, 1, 1, 0, 4, 7, 6, 4, 5, 6, 3, 2, 1, 2, 0, 6, 3,\n        6, 0, 5, 7, 5, 1, 5, 2, 2, 5, 8, 9, 5, 6, 3, 8, 8, 4, 8, 1, 6, 4, 0, 0,\n        7, 6, 2, 5, 3, 0, 5, 3, 9, 1, 3, 4, 7, 2, 5, 1, 2, 5, 0, 7, 5, 5, 6, 9,\n        8, 9, 8, 3], device='cuda:0')\ntensor([4, 1, 0, 9, 9, 9, 3, 4, 9, 5, 8, 1, 0, 1, 8, 1, 0, 2, 1, 1, 6, 5, 2, 4,\n        9, 7, 6, 2, 1, 9, 9, 3, 8, 9, 3, 9, 5, 9, 8, 9, 6, 0, 1, 0, 4, 2, 1, 4,\n        1, 1, 7, 1, 4, 2, 0, 9, 2, 7, 8, 4, 1, 3, 7, 2, 2, 2, 9, 2, 4, 8, 0, 8,\n        7, 0, 9, 7, 1, 1, 3, 9, 9, 7, 2, 3, 3, 3, 3, 4, 6, 1, 3, 0, 8, 7, 4, 2,\n        8, 2, 2, 0], device='cuda:0')\ntensor([8, 4, 6, 5, 9, 3, 0, 4, 8, 8, 7, 4, 5, 1, 8, 4, 9, 1, 9, 8, 8, 0, 0, 8,\n        6, 5, 2, 7, 0, 0, 8, 2, 8, 0, 5, 6, 6, 5, 5, 7, 5, 4, 1, 1, 5, 8, 7, 8,\n        3, 6, 5, 5, 1, 7, 6, 9, 2, 1, 2, 0, 6, 0, 0, 4, 0, 1, 3, 5, 4, 3, 3, 0,\n        9, 8, 7, 0, 4, 4, 1, 2, 1, 7, 5, 8, 0, 5, 0, 2, 7, 5, 9, 7, 1, 6, 2, 8,\n        5, 4, 8, 7], device='cuda:0')\ntensor([9, 4, 7, 5, 1, 9, 8, 5, 0, 8, 1, 1, 9, 9, 6, 1, 9, 5, 3, 0, 4, 6, 8, 9,\n        8, 2, 6, 3, 1, 0, 6, 0, 3, 0, 4, 3, 2, 3, 6, 3, 6, 5, 6, 5, 1, 3, 0, 2,\n        4, 6, 0, 3, 9, 6, 1, 1, 6, 7, 0, 8, 7, 7, 8, 2, 0, 5, 8, 4, 1, 9, 3, 3,\n        0, 9, 9, 8, 3, 8, 4, 5, 7, 5, 9, 3, 7, 1, 0, 0, 4, 2, 9, 9, 5, 5, 7, 4,\n        2, 3, 1, 1], device='cuda:0')\ntensor([6, 4, 2, 2, 4, 6, 6, 6, 3, 7, 1, 4, 0, 9, 8, 5, 8, 9, 2, 0, 2, 2, 7, 6,\n        0, 1, 4, 8, 7, 3, 1, 1, 7, 5, 1, 4, 7, 2, 2, 8, 2, 3, 4, 7, 9, 0, 1, 6,\n        2, 7, 6, 6, 5, 1, 4, 1, 2, 7, 8, 9, 9, 7, 1, 5, 5, 4, 4, 6, 0, 3, 5, 4,\n        2, 8, 6, 6, 9, 3, 4, 8, 5, 1, 3, 8, 9, 1, 7, 8, 2, 5, 4, 7, 0, 8, 6, 7,\n        8, 4, 5, 5], device='cuda:0')\ntensor([5, 7, 8, 6, 5, 7, 8, 7, 9, 4, 0, 9, 9, 4, 0, 1, 1, 0, 2, 9, 4, 2, 9, 3,\n        1, 7, 5, 3, 8, 9, 0, 5, 1, 8, 4, 1, 5, 1, 2, 4, 0, 2, 3, 8, 3, 9, 2, 8,\n        2, 5, 6, 8, 7, 2, 5, 8, 6, 8, 2, 1, 4, 5, 0, 5, 8, 6, 0, 4, 3, 6, 3, 4,\n        1, 1, 6, 6, 7, 0, 9, 4, 3, 5, 0, 5, 4, 2, 9, 6, 6, 7, 1, 0, 3, 7, 0, 1,\n        9, 8, 4, 4], device='cuda:0')\ntensor([5, 7, 0, 0, 3, 5, 6, 2, 9, 9, 2, 1, 8, 1, 6, 0, 9, 9, 0, 0, 6, 3, 5, 6,\n        4, 7, 1, 4, 1, 6, 5, 3, 3, 8, 7, 0, 3, 3, 3, 0, 7, 2, 8, 1, 3, 9, 4, 0,\n        7, 1, 9, 0, 8, 4, 9, 4, 3, 2, 4, 4, 7, 1, 9, 6, 2, 0, 8, 4, 4, 6, 5, 6,\n        7, 3, 9, 5, 8, 4, 5, 7, 3, 3, 8, 4, 4, 3, 0, 9, 6, 4, 5, 8, 2, 9, 4, 1,\n        7, 6, 6, 1], device='cuda:0')\ntensor([3, 5, 8, 1, 3, 4, 1, 8, 0, 8, 0, 5, 7, 7, 5, 0, 1, 5, 7, 5, 8, 8, 9, 8,\n        5, 7, 4, 7, 8, 7, 0, 5, 5, 8, 7, 1, 8, 6, 3, 1, 4, 7, 9, 5, 3, 9, 4, 5,\n        5, 9, 3, 3, 2, 0, 0, 0, 5, 3, 0, 6, 1, 2, 3, 6, 6, 6, 8, 2, 8, 4, 1, 7,\n        1, 9, 0, 9, 9, 7, 6, 4, 2, 7, 6, 0, 6, 8, 3, 0, 0, 0, 0, 7, 1, 6, 4, 0,\n        5, 0, 8, 2], device='cuda:0')\ntensor([0, 5, 3, 9, 0, 7, 5, 7, 7, 0, 7, 2, 3, 5, 9, 7, 6, 4, 0, 1, 5, 8, 1, 0,\n        8, 5, 2, 5, 3, 8, 3, 7, 3, 4, 6, 9, 8, 2, 7, 0, 6, 9, 5, 9, 3, 6, 4, 0,\n        4, 7, 5, 9, 8, 9, 7, 9, 6, 9, 0, 0, 1, 7, 9, 4, 5, 9, 4, 9, 6, 9, 8, 2,\n        1, 9, 3, 1, 4, 3, 5, 5, 9, 9, 3, 9, 2, 7, 7, 6, 1, 1, 1, 8, 0, 8, 8, 6,\n        0, 7, 2, 8], device='cuda:0')\ntensor([4, 4, 6, 4, 6, 0, 7, 4, 0, 6, 4, 5, 5, 0, 9, 1, 1, 6, 9, 6, 6, 4, 3, 9,\n        1, 2, 1, 8, 0, 2, 0, 1, 6, 7, 5, 7, 4, 2, 2, 4, 9, 1, 3, 8, 6, 2, 7, 0,\n        6, 4, 7, 4, 8, 1, 6, 9, 4, 3, 9, 4, 6, 5, 4, 4, 9, 8, 9, 1, 0, 7, 3, 9,\n        9, 5, 5, 7, 9, 6, 4, 4, 3, 0, 8, 5, 7, 9, 4, 7, 7, 4, 8, 1, 2, 2, 2, 2,\n        2, 6, 2, 3], device='cuda:0')\ntensor([9, 2, 2, 1, 6, 2, 4, 7, 9, 5, 0, 0, 9, 6, 9, 4, 4, 3, 1, 8, 9, 6, 8, 1,\n        2, 2, 7, 6, 1, 4, 2, 8, 6, 0, 7, 5, 8, 0, 3, 3, 8, 4, 5, 1, 1, 4, 3, 0,\n        0, 1, 5, 7, 2, 8, 2, 4, 2, 0, 4, 7, 5, 1, 0, 0, 2, 7, 2, 7, 9, 6, 6, 6,\n        4, 0, 1, 5, 9, 3, 2, 3, 6, 3, 2, 1, 9, 1, 9, 7, 1, 0, 1, 4, 0, 6, 8, 0,\n        3, 6, 8, 5], device='cuda:0')\ntensor([7, 6, 8, 2, 6, 7, 1, 1, 0, 1, 9, 2, 1, 7, 0, 0, 0, 4, 5, 5, 5, 3, 6, 8,\n        0, 4, 2, 4, 9, 4, 5, 2, 4, 4, 2, 6, 2, 6, 4, 2, 3, 4, 4, 1, 8, 7, 2, 3,\n        4, 7, 1, 6, 8, 6, 2, 4, 4, 2, 1, 1, 8, 2, 2, 4, 0, 8, 2, 9, 8, 6, 3, 6,\n        4, 2, 8, 1, 9, 0, 1, 2, 0, 3, 2, 7, 3, 2, 4, 5, 6, 9, 7, 5, 5, 0, 4, 2,\n        5, 5, 0, 1], device='cuda:0')\ntensor([4, 0, 1, 2, 5, 0, 9, 9, 8, 2, 5, 1, 6, 7, 9, 3, 1, 9, 8, 7, 7, 8, 4, 7,\n        8, 4, 2, 5, 5, 9, 3, 7, 5, 5, 3, 4, 6, 6, 8, 6, 5, 5, 2, 8, 2, 6, 6, 1,\n        1, 2, 7, 5, 1, 4, 2, 4, 6, 1, 6, 6, 5, 3, 4, 6, 7, 6, 9, 1, 4, 8, 6, 9,\n        1, 5, 3, 8, 6, 7, 9, 3, 5, 8, 4, 2, 4, 9, 9, 8, 5, 5, 2, 1, 3, 1, 0, 6,\n        8, 2, 0, 4], device='cuda:0')\ntensor([7, 8, 7, 8, 0, 2, 1, 6, 4, 8, 4, 4, 3, 8, 4, 3, 8, 9, 5, 3, 3, 2, 7, 7,\n        5, 9, 6, 0, 2, 3, 7, 8, 7, 2, 9, 8, 6, 1, 9, 5, 8, 2, 5, 4, 2, 1, 3, 8,\n        9, 5, 6, 9, 0, 6, 9, 4, 5, 9, 1, 7, 5, 5, 8, 2, 0, 7, 1, 5, 6, 6, 2, 0,\n        1, 1, 9, 7, 6, 0, 0, 9, 7, 6, 7, 5, 4, 4, 1, 2, 1, 2, 2, 5, 5, 2, 0, 9,\n        2, 3, 2, 5], device='cuda:0')\ntensor([4, 0, 8, 1, 7, 3, 2, 0, 7, 1, 8, 4, 7, 3, 4, 3, 5, 5, 1, 4, 7, 1, 8, 3,\n        1, 9, 9, 3, 6, 9, 5, 5, 7, 2, 5, 5, 7, 5, 7, 8, 2, 3, 4, 3, 2, 8, 8, 8,\n        5, 2, 6, 2, 7, 7, 3, 3, 6, 6, 0, 8, 4, 3, 2, 9, 1, 4, 4, 4, 6, 2, 3, 9,\n        5, 6, 4, 9, 6, 8, 7, 8, 9, 3, 7, 9, 5, 0, 9, 9, 5, 4, 1, 6, 0, 9, 8, 9,\n        2, 8, 9, 7], device='cuda:0')\ntensor([6, 1, 2, 6, 8, 3, 9, 8, 1, 9, 7, 8, 3, 1, 6, 6, 2, 2, 8, 6, 2, 1, 5, 4,\n        6, 9, 6, 9, 1, 2, 4, 5, 0, 5, 4, 7, 7, 2, 1, 5, 7, 6, 5, 9, 3, 2, 8, 7,\n        5, 5, 1, 1, 2, 9, 8, 9, 2, 3, 8, 2, 9, 3, 0, 9, 8, 3, 2, 8, 5, 6, 0, 4,\n        6, 4, 7, 1, 7, 9, 7, 7, 4, 2, 5, 5, 2, 8, 7, 6, 3, 6, 5, 3, 8, 1, 4, 9,\n        1, 4, 0, 1], device='cuda:0')\ntensor([9, 2, 3, 6, 0, 8, 9, 1, 4, 8, 8, 0, 3, 4, 2, 7, 7, 0, 7, 4, 7, 4, 4, 0,\n        6, 0, 5, 6, 0, 3, 6, 7, 1, 9, 6, 2, 4, 7, 3, 7, 7, 3, 8, 9, 5, 6, 9, 7,\n        4, 9, 1, 6, 8, 9, 1, 3, 9, 7, 1, 4, 1, 6, 7, 6, 0, 9, 4, 3, 6, 2, 9, 5,\n        7, 2, 3, 0, 4, 5, 3, 0, 4, 3, 3, 0, 8, 7, 4, 0, 6, 7, 6, 5, 2, 3, 3, 4,\n        4, 1, 6, 9], device='cuda:0')\ntensor([2, 4, 8, 2, 4, 4, 5, 1, 2, 5, 9, 9, 8, 4, 8, 5, 9, 7, 8, 0, 3, 4, 4, 0,\n        9, 3, 3, 9, 4, 3, 1, 2, 6, 2, 7, 2, 9, 0, 5, 2, 4, 3, 7, 0, 9, 2, 0, 2,\n        9, 2, 6, 2, 5, 7, 5, 0, 8, 9, 9, 0, 7, 7, 7, 8, 5, 1, 5, 4, 1, 0, 3, 6,\n        1, 6, 7, 1, 5, 6, 8, 5, 1, 1, 8, 4, 8, 0, 3, 6, 5, 7, 6, 9, 2, 6, 5, 5,\n        9, 7, 5, 3], device='cuda:0')\ntensor([6, 7, 6, 3, 8, 3, 1, 2, 5, 2, 7, 3, 2, 2, 0, 0, 1, 2, 9, 8, 4, 3, 3, 3,\n        6, 3, 7, 4, 1, 8, 6, 3, 9, 4, 4, 7, 2, 5, 1, 4, 5, 8, 6, 3, 6, 7, 7, 5,\n        3, 4, 4, 4, 3, 8, 3, 4, 2, 8, 8, 4, 6, 8, 3, 2, 0, 4, 9, 3, 7, 8, 8, 1,\n        5, 3, 9, 1, 5, 5, 3, 9, 1, 2, 3, 1, 1, 0, 0, 6, 4, 7, 1, 6, 5, 3, 2, 5,\n        7, 5, 0, 5], device='cuda:0')\ntensor([1, 0, 4, 8, 0, 4, 9, 5, 1, 4, 8, 0, 6, 7, 4, 3, 4, 5, 2, 4, 3, 2, 1, 5,\n        4, 5, 1, 5, 9, 0, 7, 6, 3, 3, 7, 3, 2, 2, 0, 1, 5, 3, 2, 4, 1, 7, 6, 9,\n        1, 2, 5, 5, 1, 7, 6, 6, 3, 1, 0, 3, 1, 3, 0, 2, 9, 2, 1, 7, 5, 6, 1, 7,\n        3, 5, 7, 2, 9, 8, 5, 4, 7, 9, 6, 6, 5, 2, 4, 8, 4, 1, 7, 4, 2, 3, 9, 2,\n        6, 3, 9, 2], device='cuda:0')\ntensor([4, 8, 8, 3, 4, 7, 4, 1, 3, 9, 4, 7, 8, 6, 5, 6, 2, 0, 1, 9, 0, 3, 6, 7,\n        9, 6, 3, 8, 9, 2, 5, 6, 2, 7, 6, 0, 4, 4, 9, 0, 5, 1, 0, 8, 4, 2, 5, 5,\n        2, 1, 5, 5, 6, 1, 3, 5, 5, 3, 5, 0, 1, 8, 1, 3, 2, 3, 2, 5, 7, 5, 4, 0,\n        6, 0, 0, 6, 3, 6, 7, 9, 2, 2, 2, 3, 9, 3, 4, 4, 7, 3, 7, 9, 5, 8, 9, 1,\n        6, 2, 9, 3], device='cuda:0')\ntensor([9, 7, 7, 3, 2, 1, 3, 0, 1, 0, 6, 6, 1, 3, 1, 0, 4, 6, 4, 1, 9, 9, 8, 1,\n        1, 2, 2, 7, 8, 9, 4, 5, 7, 6, 9, 3, 1, 4, 4, 6, 0, 0, 7, 7, 7, 5, 9, 5,\n        3, 8, 8, 6, 8, 3, 4, 6, 6, 5, 0, 5, 6, 8, 5, 1, 2, 1, 0, 1, 0, 5, 5, 7,\n        6, 0, 0, 8, 5, 1, 0, 1, 6, 4, 2, 9, 9, 8, 5, 0, 0, 1, 1, 7, 7, 8, 9, 8,\n        3, 6, 5, 1], device='cuda:0')\ntensor([3, 8, 3, 1, 4, 4, 5, 4, 3, 3, 3, 1, 4, 5, 0, 0, 6, 8, 5, 4, 1, 1, 8, 8,\n        7, 2, 6, 6, 5, 7, 5, 8, 2, 0, 4, 6, 9, 9, 7, 4, 0, 4, 8, 3, 7, 1, 1, 9,\n        4, 5, 8, 9, 9, 3, 5, 1, 8, 7, 6, 1, 0, 2, 2, 5, 0, 8, 8, 0, 4, 7, 4, 7,\n        4, 9, 9, 0, 8, 6, 8, 1, 2, 0, 8, 1, 2, 5, 2, 2, 0, 9, 9, 4, 5, 4, 4, 5,\n        3, 1, 8, 3], device='cuda:0')\ntensor([5, 0, 4, 7, 2, 4, 5, 0, 8, 6, 2, 0, 4, 1, 1, 0, 5, 1, 6, 4, 6, 2, 1, 8,\n        5, 6, 3, 1, 6, 2, 1, 3, 1, 5, 2, 5, 3, 8, 1, 2, 6, 6, 1, 7, 4, 8, 9, 9,\n        9, 5, 9, 7, 6, 6, 2, 7, 0, 6, 2, 8, 9, 8, 5, 6, 9, 6, 1, 5, 0, 1, 3, 3,\n        1, 8, 3, 6, 0, 5, 9, 2, 4, 6, 0, 7, 7, 7, 6, 4, 6, 4, 7, 0, 1, 3, 7, 3,\n        4, 4, 8, 7], device='cuda:0')\ntensor([8, 0, 1, 9, 7, 8, 0, 5, 2, 5, 2, 7, 2, 6, 2, 8, 3, 2, 7, 7, 6, 8, 5, 3,\n        6, 3, 6, 2, 3, 6, 4, 1, 0, 5, 0, 4, 9, 4, 1, 8, 3, 1, 5, 1, 7, 8, 5, 2,\n        1, 9, 8, 7, 3, 0, 4, 8, 9, 8, 4, 7, 8, 8, 9, 1, 5, 7, 1, 3, 2, 2, 1, 8,\n        5, 7, 4, 8, 3, 5, 0, 0, 8, 8, 4, 3, 8, 4, 0, 7, 2, 4, 2, 5, 0, 6, 9, 7,\n        1, 1, 9, 5], device='cuda:0')\ntensor([9, 4, 7, 5, 0, 5, 5, 0, 9, 9, 1, 5, 7, 1, 9, 1, 3, 0, 5, 8, 0, 9, 9, 6,\n        1, 9, 8, 1, 5, 3, 0, 8, 6, 1, 9, 7, 3, 6, 9, 9, 7, 4, 2, 0, 8, 8, 2, 4,\n        5, 4, 0, 5, 9, 4, 8, 5, 8, 0, 4, 8, 1, 7, 2, 8, 6, 4, 3, 6, 2, 5, 5, 0,\n        2, 3, 6, 7, 2, 6, 9, 5, 0, 9, 3, 9, 3, 5, 9, 3, 9, 4, 5, 0, 1, 0, 1, 9,\n        8, 4, 2, 7], device='cuda:0')\ntensor([4, 8, 3, 7, 9, 6, 8, 0, 9, 7, 6, 1, 2, 0, 1, 6, 9, 7, 9, 2, 5, 5, 9, 1,\n        6, 1, 2, 6, 6, 8, 6, 1, 6, 6, 9, 0, 9, 0, 0, 0, 2, 8, 1, 8, 4, 4, 3, 5,\n        2, 0, 5, 9, 1, 5, 7, 3, 5, 3, 9, 6, 4, 6, 7, 7, 1, 2, 4, 4, 8, 1, 7, 2,\n        6, 6, 4, 8, 9, 1, 0, 7, 1, 6, 8, 8, 3, 1, 7, 4, 2, 8, 3, 2, 1, 3, 0, 5,\n        5, 3, 4, 6], device='cuda:0')\ntensor([1, 9, 6, 3, 0, 2, 2, 4, 0, 6, 6, 9, 9, 1, 6, 2, 6, 2, 0, 2, 5, 1, 2, 9,\n        7, 0, 7, 8, 9, 9, 5, 2, 2, 0, 9, 1, 6, 1, 3, 7, 9, 9, 4, 6, 7, 1, 2, 7,\n        8, 3, 3, 1, 5, 3, 9, 4, 0, 6, 4, 8, 2, 4, 7, 7, 4, 0, 6, 4, 9, 5, 3, 9,\n        7, 9, 7, 0, 6, 1, 0, 7, 1, 1, 1, 9, 5, 7, 4, 8, 7, 0, 6, 8, 0, 6, 9, 9,\n        5, 4, 6, 2], device='cuda:0')\ntensor([9, 9, 7, 4, 5, 1, 3, 3, 6, 2, 6, 1, 1, 7, 3, 3, 8, 4, 1, 7, 1, 0, 4, 6,\n        1, 9, 1, 2, 0, 7, 0, 9, 7, 7, 2, 8, 8, 8, 7, 0, 5, 0, 3, 2, 5, 0, 0, 0,\n        6, 8, 4, 4, 9, 4, 5, 7, 7, 8, 6, 6, 6, 0, 9, 6, 1, 1, 7, 7, 5, 6, 0, 3,\n        9, 9, 6, 2, 4, 4, 4, 2, 3, 0, 0, 1, 2, 2, 5, 1, 2, 7, 5, 6, 0, 9, 7, 4,\n        0, 1, 9, 8], device='cuda:0')\ntensor([5, 6, 2, 1, 6, 1, 9, 3, 8, 5, 3, 3, 8, 8, 2, 9, 6, 1, 4, 3, 9, 4, 7, 5,\n        7, 6, 9, 5, 3, 5, 8, 5, 6, 8, 0, 4, 4, 9, 7, 9, 5, 9, 5, 7, 1, 1, 6, 9,\n        3, 6, 6, 3, 0, 7, 0, 1, 1, 0, 6, 6, 6, 0, 5, 8, 1, 0, 6, 3, 2, 2, 5, 0,\n        9, 8, 5, 5, 4, 7, 1, 8, 8, 0, 9, 7, 0, 0, 4, 2, 5, 3, 7, 0, 4, 8, 1, 1,\n        8, 6, 2, 2], device='cuda:0')\ntensor([9, 6, 1, 9, 6, 2, 8, 4, 2, 2, 9, 8, 6, 4, 7, 4, 6, 4, 5, 2, 2, 8, 5, 2,\n        1, 3, 6, 3, 8, 7, 6, 6, 4, 3, 7, 1, 2, 5, 1, 4, 3, 4, 7, 6, 8, 9, 1, 4,\n        7, 0, 9, 1, 2, 7, 8, 9, 2, 6, 1, 5, 4, 3, 2, 2, 8, 5, 5, 8, 7, 9, 6, 6,\n        9, 5, 1, 1, 3, 6, 1, 2, 9, 7, 1, 1, 9, 2, 3, 1, 4, 8, 7, 5, 9, 0, 5, 6,\n        4, 5, 5, 0], device='cuda:0')\ntensor([8, 9, 2, 4, 6, 4, 4, 8, 2, 6, 3, 3, 0, 8, 3, 8, 4, 9, 3, 9, 9, 3, 4, 6,\n        7, 0, 1, 4, 1, 1, 7, 8, 1, 6, 8, 7, 5, 7, 3, 1, 1, 8, 5, 8, 2, 9, 7, 2,\n        1, 1, 3, 3, 2, 3, 4, 9, 5, 3, 1, 2, 6, 7, 8, 7, 5, 2, 5, 3, 1, 8, 8, 1,\n        3, 0, 1, 4, 5, 1, 4, 6, 5, 6, 5, 2, 9, 2, 9, 7, 9, 0, 5, 1, 9, 9, 4, 8,\n        6, 0, 7, 3], device='cuda:0')\ntensor([5, 3, 1, 2, 6, 4, 6, 7, 1, 6, 3, 0, 8, 3, 7, 4, 8, 1, 2, 0, 4, 2, 1, 8,\n        1, 3, 2, 7, 9, 1, 8, 0, 2, 7, 1, 4, 9, 3, 7, 6, 3, 9, 0, 7, 5, 3, 3, 0,\n        5, 5, 1, 3, 7, 8, 2, 5, 6, 0, 5, 9, 9, 9, 3, 5, 2, 9, 7, 8, 1, 5, 1, 1,\n        4, 2, 9, 2, 8, 1, 8, 4, 6, 3, 6, 1, 7, 3, 3, 0, 9, 9, 7, 1, 2, 7, 4, 3,\n        5, 5, 4, 6], device='cuda:0')\ntensor([0, 9, 2, 6, 0, 0, 9, 8, 9, 8, 1, 5, 5, 0, 0, 7, 9, 9, 7, 3, 4, 5, 2, 9,\n        4, 3, 2, 1, 0, 6, 0, 2, 7, 1, 0, 2, 3, 5, 9, 7, 4, 0, 7, 5, 9, 0, 6, 7,\n        9, 7, 1, 4, 8, 0, 7, 2, 5, 1, 8, 7, 7, 7, 5, 5, 2, 1, 5, 5, 5, 7, 9, 4,\n        6, 0, 3, 7, 5, 7, 5, 3, 1, 4, 9, 2, 6, 1, 1, 6, 9, 4, 1, 0, 8, 0, 5, 4,\n        6, 7, 7, 9], device='cuda:0')\ntensor([4, 9, 7, 6, 3, 7, 0, 8, 8, 7, 9, 2, 4, 2, 1, 4, 3, 2, 3, 8, 6, 9, 0, 5,\n        6, 9, 3, 2, 5, 2, 0, 6, 7, 6, 2, 9, 2, 3, 5, 0, 6, 5, 0, 2, 1, 1, 9, 4,\n        7, 2, 3, 9, 6, 6, 4, 2, 1, 8, 8, 5, 1, 0, 3, 4, 3, 5, 6, 5, 5, 1, 1, 3,\n        2, 1, 0, 3, 3, 9, 4, 5, 0, 3, 3, 9, 9, 7, 1, 9, 0, 4, 2, 4, 3, 9, 8, 3,\n        7, 0, 4, 9], device='cuda:0')\ntensor([3, 3, 9, 3, 9, 2, 2, 6, 9, 6, 3, 3, 9, 6, 6, 7, 1, 3, 1, 9, 8, 3, 6, 8,\n        1, 0, 5, 9, 4, 5, 1, 6, 0, 2, 7, 3, 6, 5, 8, 2, 3, 7, 7, 2, 3, 4, 7, 9,\n        5, 0, 1, 8, 3, 0, 5, 5, 6, 3, 7, 5, 2, 9, 8, 8, 3, 1, 8, 5, 6, 4, 8, 5,\n        7, 2, 2, 1, 6, 7, 9, 2, 1, 7, 1, 8, 7, 8, 5, 4, 5, 7, 8, 2, 2, 1, 0, 9,\n        6, 0, 8, 8], device='cuda:0')\ntensor([2, 4, 2, 6, 9, 5, 2, 9, 8, 5, 1, 2, 1, 1, 2, 4, 4, 9, 4, 6, 9, 6, 4, 6,\n        9, 1, 0, 3, 9, 8, 6, 9, 2, 6, 8, 9, 4, 6, 4, 8, 7, 5, 2, 2, 6, 1, 7, 6,\n        4, 4, 0, 6, 4, 9, 8, 9, 9, 4, 3, 9, 3, 4, 9, 2, 3, 8, 4, 6, 1, 5, 4, 1,\n        2, 1, 8, 4, 2, 1, 0, 1, 5, 2, 8, 7, 6, 8, 3, 1, 3, 7, 7, 1, 8, 5, 0, 2,\n        1, 8, 8, 4], device='cuda:0')\ntensor([3, 9, 5, 2, 8, 1, 9, 4, 9, 1, 7, 8, 7, 3, 9, 8, 2, 6, 3, 5, 2, 2, 9, 6,\n        8, 6, 3, 7, 8, 9, 7, 8, 3, 6, 5, 0, 7, 8, 9, 7, 0, 3, 6, 5, 1, 1, 0, 4,\n        2, 1, 4, 8, 6, 2, 5, 7, 9, 3, 1, 3, 7, 6, 2, 4, 8, 5, 9, 7, 4, 6, 8, 2,\n        3, 4, 0, 1, 5, 9, 4, 3, 9, 9, 6, 7, 5, 7, 8, 8, 1, 1, 1, 8, 1, 6, 3, 2,\n        1, 6, 4, 8], device='cuda:0')\ntensor([2, 2, 3, 6, 7, 6, 8, 1, 3, 1, 6, 7, 5, 7, 4, 8, 6, 9, 6, 3, 3, 3, 5, 1,\n        6, 8, 4, 5, 4, 7, 6, 6, 9, 9, 3, 2, 4, 6, 3, 5, 2, 9, 7, 2, 7, 6, 1, 9,\n        5, 2, 9, 0, 7, 6, 1, 3, 1, 8, 2, 1, 7, 5, 7, 8, 4, 2, 6, 1, 3, 9, 1, 4,\n        6, 9, 1, 9, 4, 2, 9, 5, 8, 4, 2, 7, 2, 1, 6, 9, 9, 6, 8, 4, 8, 1, 3, 9,\n        4, 1, 8, 7], device='cuda:0')\ntensor([1, 0, 2, 2, 7, 7, 1, 6, 3, 5, 0, 6, 2, 9, 3, 1, 0, 5, 7, 3, 3, 4, 7, 9,\n        7, 8, 4, 8, 8, 2, 0, 5, 9, 4, 1, 8, 8, 0, 1, 5, 9, 6, 6, 1, 1, 7, 8, 0,\n        0, 2, 0, 7, 1, 2, 4, 0, 3, 4, 1, 8, 6, 5, 9, 6, 5, 3, 3, 4, 5, 2, 3, 5,\n        0, 5, 3, 7, 5, 4, 7, 2, 8, 6, 6, 5, 3, 6, 7, 1, 2, 0, 4, 2, 9, 9, 0, 6,\n        1, 8, 1, 1], device='cuda:0')\ntensor([7, 8, 9, 4, 5, 2, 9, 2, 1, 2, 6, 1, 0, 7, 8, 2, 1, 0, 7, 5, 7, 7, 8, 5,\n        1, 2, 5, 6, 0, 1, 5, 1, 7, 7, 0, 0, 4, 3, 7, 6, 9, 6, 9, 8, 7, 8, 6, 8,\n        7, 0, 1, 3, 4, 9, 1, 6, 8, 5, 4, 8, 2, 7, 7, 7, 0, 4, 9, 0, 1, 8, 4, 5,\n        0, 2, 4, 6, 1, 1, 9, 2, 4, 3, 8, 2, 7, 9, 6, 3, 2, 8, 1, 5, 6, 4, 5, 6,\n        7, 7, 6, 6], device='cuda:0')\ntensor([9, 0, 8, 8, 3, 8, 0, 7, 5, 8, 1, 9, 1, 3, 3, 5, 9, 5, 7, 8, 9, 8, 0, 8,\n        3, 0, 0, 2, 7, 4, 2, 2, 0, 6, 4, 2, 2, 0, 6, 0, 0, 3, 1, 7, 0, 8, 6, 4,\n        7, 5, 5, 0, 3, 5, 5, 5, 2, 4, 0, 6, 5, 8, 0, 0, 0, 2, 8, 4, 2, 5, 5, 3,\n        6, 9, 8, 4, 4, 0, 6, 9, 5, 4, 6, 0, 6, 9, 1, 8, 2, 1, 9, 3, 2, 5, 7, 2,\n        6, 6, 5, 3], device='cuda:0')\ntensor([9, 6, 5, 4, 9, 0, 1, 8, 2, 1, 3, 7, 9, 1, 3, 6, 6, 3, 1, 5, 6, 0, 4, 0,\n        6, 6, 6, 8, 4, 6, 3, 6, 1, 2, 6, 0, 3, 0, 4, 4, 6, 8, 7, 6, 2, 3, 7, 2,\n        3, 6, 3, 7, 0, 9, 4, 0, 3, 3, 7, 1, 1, 4, 5, 2, 9, 1, 3, 5, 1, 5, 9, 8,\n        6, 4, 1, 2, 5, 4, 8, 6, 6, 8, 6, 8, 2, 8, 9, 9, 3, 5, 9, 6, 3, 9, 6, 4,\n        6, 0, 7, 3], device='cuda:0')\ntensor([2, 4, 3, 5, 4, 6, 9, 5, 7, 7, 8, 3, 0, 4, 4, 3, 0, 2, 3, 9, 4, 0, 2, 7,\n        4, 7, 8, 0, 1, 4, 3, 7, 2, 2, 4, 9, 3, 8, 6, 8, 0, 2, 4, 7, 8, 0, 1, 9,\n        5, 2, 6, 7, 7, 5, 7, 5, 2, 2, 6, 3, 0, 8, 3, 3, 2, 3, 5, 3, 6, 0, 7, 6,\n        9, 4, 3, 1, 6, 7, 9, 9, 1, 8, 5, 5, 4, 8, 9, 4, 1, 2, 6, 4, 3, 2, 4, 1,\n        1, 1, 6, 3], device='cuda:0')\npredictions_tensor size torch.Size([5000])\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\nresult_df=test_df[['id']]\n\nresult_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:56:51.895711Z","iopub.execute_input":"2022-08-17T16:56:51.896137Z","iopub.status.idle":"2022-08-17T16:56:52.321948Z","shell.execute_reply.started":"2022-08-17T16:56:51.896098Z","shell.execute_reply":"2022-08-17T16:56:52.320286Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"   id\n0   0\n1   1\n2   2\n3   3\n4   4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"result_df['label'] = predictions_tensor.cpu().numpy()\nresult_df","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:56:54.095269Z","iopub.execute_input":"2022-08-17T16:56:54.095952Z","iopub.status.idle":"2022-08-17T16:56:54.111551Z","shell.execute_reply.started":"2022-08-17T16:56:54.095917Z","shell.execute_reply":"2022-08-17T16:56:54.110441Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"        id  label\n0        0      3\n1        1      0\n2        2      2\n3        3      6\n4        4      7\n...    ...    ...\n4995  4995      1\n4996  4996      1\n4997  4997      1\n4998  4998      6\n4999  4999      3\n\n[5000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>4995</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>4996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>4997</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>4998</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>4999</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"result_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:56:57.435960Z","iopub.execute_input":"2022-08-17T16:56:57.436333Z","iopub.status.idle":"2022-08-17T16:56:57.450093Z","shell.execute_reply.started":"2022-08-17T16:56:57.436303Z","shell.execute_reply":"2022-08-17T16:56:57.449087Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#we will use train dataset itself for time being\n# model.eval()\n\n# with torch.no_grad():\n#     all_train_preds = []\n#     cnt = 0 \n#     for i, data in enumerate(val_data_loader):\n#         cnt+=1 \n        \n#         image =data[0]\n#         label = data[1]\n                  \n#         train_output = model(image) \n#         max_pred = train_output.argmax(axis=1)\n        \n#         print ('label size',label.size())\n#         print ('max_pred size',max_pred.size())\n        \n#         print ('label ',label)\n#         print ('max_pred ',max_pred)\n        \n#         mask = label == max_pred\n        \n#         print ('mask',mask)\n        \n#         matching_values = max_pred[mask]\n        \n#         print ('matching_values size',matching_values.size())\n        \n#         print ('matching_values',matching_values)\n            \n        \n#         break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T01:35:10.052637Z","iopub.execute_input":"2022-08-17T01:35:10.053047Z","iopub.status.idle":"2022-08-17T01:35:10.112026Z","shell.execute_reply.started":"2022-08-17T01:35:10.053011Z","shell.execute_reply":"2022-08-17T01:35:10.110583Z"},"trusted":true},"execution_count":null,"outputs":[]}]}