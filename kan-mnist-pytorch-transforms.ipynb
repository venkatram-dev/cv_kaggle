{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-17T16:24:38.197653Z","iopub.execute_input":"2022-08-17T16:24:38.198086Z","iopub.status.idle":"2022-08-17T16:24:38.208007Z","shell.execute_reply.started":"2022-08-17T16:24:38.198048Z","shell.execute_reply":"2022-08-17T16:24:38.206801Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"/kaggle/input/Kannada-MNIST/sample_submission.csv\n/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\n/kaggle/input/Kannada-MNIST/train.csv\n/kaggle/input/Kannada-MNIST/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchvision import transforms\n\n#my_tranforms = transforms.Compose ([transforms.ToTensor()])\nmy_tranforms = transforms.Compose ([ transforms.ToPILImage(), transforms.ToTensor()])\n\n#my_tranforms = transforms.Compose ([ transforms.ToPILImage()])\n\n#my_tranforms = transforms.Compose ([transforms.ToTensor(),transforms.Normalize((0.5, ), (0.5, ))])\n","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:38.342519Z","iopub.execute_input":"2022-08-17T16:24:38.343573Z","iopub.status.idle":"2022-08-17T16:24:38.349111Z","shell.execute_reply.started":"2022-08-17T16:24:38.343534Z","shell.execute_reply":"2022-08-17T16:24:38.347912Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\n\n\nclass kan_dataset(Dataset):\n    def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n        df = pd.read_csv(csv_file)\n        self.test_data = test_data\n        if self.test_data ==0:\n            self.y = df['label']\n            self.y = self.y.to_numpy()\n        else:\n            self.y = None\n        \n        self.x = df.iloc[:,1:]\n        \n        self.x = self.x.to_numpy().astype(np.uint8)\n        \n        #self.x = self.x.to_numpy().astype(float)\n        #self.x = self.x.to_numpy()\n        #self.x = self.x.reshape(self.x.shape[0],1,28,28)\n        \n        #numpy images have color channels last \n        self.x = self.x.reshape(self.x.shape[0],28,28,1)\n        \n        self.transform = transform\n        \n        #print ('self.x',self.x)\n        \n    def __len__(self):\n        return (len(self.x))\n    \n    def __getitem__(self, idx):\n        data = self.x[idx]\n        transformed_data = self.transform (data)\n        if self.test_data ==0:\n            label = self.y[idx]\n            return transformed_data, label\n        else:\n            return transformed_data\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:38.490375Z","iopub.execute_input":"2022-08-17T16:24:38.490784Z","iopub.status.idle":"2022-08-17T16:24:38.502106Z","shell.execute_reply.started":"2022-08-17T16:24:38.490749Z","shell.execute_reply":"2022-08-17T16:24:38.501315Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"kan_train_data = kan_dataset('/kaggle/input/Kannada-MNIST/train.csv',transform=my_tranforms)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:38.642939Z","iopub.execute_input":"2022-08-17T16:24:38.643920Z","iopub.status.idle":"2022-08-17T16:24:42.113583Z","shell.execute_reply.started":"2022-08-17T16:24:38.643858Z","shell.execute_reply":"2022-08-17T16:24:42.112306Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size =100\ntrain_data_loader = DataLoader(kan_train_data,batch_size=batch_size,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.116985Z","iopub.execute_input":"2022-08-17T16:24:42.117892Z","iopub.status.idle":"2022-08-17T16:24:42.128740Z","shell.execute_reply.started":"2022-08-17T16:24:42.117840Z","shell.execute_reply":"2022-08-17T16:24:42.122543Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"for i,(data,labels) in enumerate(train_data_loader):\n    print ('data shape',data.size())\n    img1 = data[0]\n    print ('img1 shape',img1.size())\n    print ('img1 ',img1)\n    break\n    \n    #For this case using ([ transforms.ToPILImage(), transforms.ToTensor()]) results in same result as dividing numpy array by 255\n    # values match with https://www.kaggle.com/venkatram123/kan-mnist-pytorch\n    \n# data shape torch.Size([5, 1, 28, 28])\n# img1 shape torch.Size([1, 28, 28])\n# img1  tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.9176, 1.0000,\n#           1.0000, 0.5843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.9176, 1.0000,\n#           1.0000, 0.9059, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.6549, 0.9686, 1.0000,\n#           1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.1961, 0.6039, 1.0000, 1.0000, 0.6431,\n#           0.5255, 0.7216, 0.8667, 0.4745, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.1882, 0.6039, 0.9176, 0.6745, 0.6745, 0.1686,\n#           0.0000, 0.2824, 0.6745, 0.6745, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.133802Z","iopub.execute_input":"2022-08-17T16:24:42.134680Z","iopub.status.idle":"2022-08-17T16:24:42.170516Z","shell.execute_reply.started":"2022-08-17T16:24:42.134633Z","shell.execute_reply":"2022-08-17T16:24:42.169357Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"data shape torch.Size([100, 1, 28, 28])\nimg1 shape torch.Size([1, 28, 28])\nimg1  tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.4784, 1.0000, 1.0000,\n          0.2863, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0392, 0.4471, 0.9333, 0.8510, 0.8510,\n          0.9608, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.2510, 0.9137, 0.4118, 0.0000, 0.0000,\n          0.7490, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0510, 0.5137, 0.6510, 0.0000, 0.0000, 0.0000,\n          0.7490, 0.4471, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.1490, 0.8863, 0.3569, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0275, 0.6157, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0510, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.2627, 0.9020, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0510, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.8510, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0510, 0.8706, 0.1137, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.8510, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0510, 0.8510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.8510, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0980, 0.8510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.8510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.7608, 0.8510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0510, 0.8510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0471, 0.8510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0471, 0.9333, 0.4118, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0510, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0118, 0.2510, 0.1882, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7490, 1.0000, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.1137, 0.8706, 0.8588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.8510, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000]]])\n","output_type":"stream"}]},{"cell_type":"code","source":"#without any transforms\n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy()\n#         self.x = self.x.reshape(self.x.shape[0],1,28,28)\n        \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n        \n#         return data, label\n    \n    \n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n    \n# data shape torch.Size([5, 1, 28, 28])","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.173596Z","iopub.execute_input":"2022-08-17T16:24:42.174019Z","iopub.status.idle":"2022-08-17T16:24:42.180312Z","shell.execute_reply.started":"2022-08-17T16:24:42.173978Z","shell.execute_reply":"2022-08-17T16:24:42.178932Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# with \n\n# my_tranforms = transforms.Compose ([transforms.ToTensor()])\n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy()\n#         self.x = self.x.reshape(self.x.shape[0],1,28,28)\n\n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n    \n\n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n\n# data shape torch.Size([5, 28, 1, 28])\n\n# this is because ToTensor assumes that image is of Height,Width, Color_Channels and converts it to Color_Channels,Height,Width","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.182109Z","iopub.execute_input":"2022-08-17T16:24:42.182756Z","iopub.status.idle":"2022-08-17T16:24:42.194889Z","shell.execute_reply.started":"2022-08-17T16:24:42.182714Z","shell.execute_reply":"2022-08-17T16:24:42.193687Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# with transform to pil \n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy()\n#         self.x = self.x.reshape(self.x.shape[0],1,28,28)\n\n    \n    \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n    \n#     for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n\n#     ValueError: pic should not have > 4 channels. Got 28 channels.","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.196592Z","iopub.execute_input":"2022-08-17T16:24:42.197255Z","iopub.status.idle":"2022-08-17T16:24:42.211075Z","shell.execute_reply.started":"2022-08-17T16:24:42.197214Z","shell.execute_reply":"2022-08-17T16:24:42.209893Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#with just to tensor and different reshape \n\n# my_tranforms = transforms.Compose ([transforms.ToTensor()])\n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy()\n#         #self.x = self.x.reshape(self.x.shape[0],1,28,28)\n#         self.x = self.x.reshape(self.x.shape[0],28,28,1)\n        \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n    \n#     for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n\n#     data shape torch.Size([5, 1, 28, 28])\n","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.212753Z","iopub.execute_input":"2022-08-17T16:24:42.213453Z","iopub.status.idle":"2022-08-17T16:24:42.222586Z","shell.execute_reply.started":"2022-08-17T16:24:42.213401Z","shell.execute_reply":"2022-08-17T16:24:42.221483Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# with pil image transform\n\n# my_tranforms = transforms.Compose ([ transforms.ToPILImage(), transforms.ToTensor()])\n\n# TypeError: Input type int64 is not supported","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.223960Z","iopub.execute_input":"2022-08-17T16:24:42.224681Z","iopub.status.idle":"2022-08-17T16:24:42.237184Z","shell.execute_reply.started":"2022-08-17T16:24:42.224640Z","shell.execute_reply":"2022-08-17T16:24:42.236052Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# to fix above convert to unit8\n\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy().astype(np.uint8)\n#         self.x = self.x.reshape(self.x.shape[0],28,28,1)\n        \n    \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n    \n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     break\n    \n# data shape torch.Size([5, 1, 28, 28])","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.238829Z","iopub.execute_input":"2022-08-17T16:24:42.239547Z","iopub.status.idle":"2022-08-17T16:24:42.250198Z","shell.execute_reply.started":"2022-08-17T16:24:42.239504Z","shell.execute_reply":"2022-08-17T16:24:42.249138Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# just to tensor does not do any normalize\n\n# sample output \n\n# img1  tensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n#             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21,\n#           234, 255, 255, 149,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21,\n#           234, 255, 255, 231, 148,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 167,\n#           247, 255, 255, 255, 191,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  50, 154, 255,\n#           255, 164, 134, 184, 221, 121,   0,   0,   0,   0,   0,   0,   0,   0],\n#          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 154, 234, 172,\n#           172,  43,   0,  72, 172, 172,   0,   0,   0,   0,   0,   0,   0,   0],\n               \n               ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.255502Z","iopub.execute_input":"2022-08-17T16:24:42.256254Z","iopub.status.idle":"2022-08-17T16:24:42.266476Z","shell.execute_reply.started":"2022-08-17T16:24:42.256217Z","shell.execute_reply":"2022-08-17T16:24:42.265318Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# use to_tensor and to_normalize,\n# does not do correctly\n\n\n# img1  tensor([[[ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  41., 467., 509., 509., 297.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  41., 467., 509., 509., 461., 295.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            -1.,  79., 333., 493., 509., 509., 509., 381.,  -1.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n#            99., 307., 509., 509., 327., 267., 367., 441., 241.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n#          [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  95.,\n#           307., 467., 343., 343.,  85.,  -1., 143., 343., 343.,  -1.,  -1.,\n#            -1.,  -1.,  -1.,  -1.,  -1.,  -1.],","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.268650Z","iopub.execute_input":"2022-08-17T16:24:42.269038Z","iopub.status.idle":"2022-08-17T16:24:42.282034Z","shell.execute_reply.started":"2022-08-17T16:24:42.268999Z","shell.execute_reply":"2022-08-17T16:24:42.280988Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# pil transform alone\n\n# my_tranforms = transforms.Compose ([ transforms.ToPILImage()])\n\n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     img1 = data[0]\n#     print ('img1 shape',img1.size())\n#     print ('img1 ',img1)\n#     break\n\n# TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.285331Z","iopub.execute_input":"2022-08-17T16:24:42.286538Z","iopub.status.idle":"2022-08-17T16:24:42.295992Z","shell.execute_reply.started":"2022-08-17T16:24:42.286489Z","shell.execute_reply":"2022-08-17T16:24:42.294764Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# using pil transform and to tensor is correct way to go\n\n# my_tranforms = transforms.Compose ([ transforms.ToPILImage(), transforms.ToTensor()])\n\n\n# class kan_dataset(Dataset):\n#     def __init__(self, csv_file, test_data=0, transform=my_tranforms):\n#         df = pd.read_csv(csv_file)\n#         self.y = df['label']\n        \n#         self.x = df.iloc[:,1:]\n        \n#         self.x = self.x.to_numpy().astype(np.uint8)\n        \n#         #self.x = self.x.to_numpy().astype(float)\n        \n#         #self.x = self.x.to_numpy()\n\n#         #self.x = self.x.reshape(self.x.shape[0],1,28,28)\n#         self.x = self.x.reshape(self.x.shape[0],28,28,1)\n        \n#         self.transform = transform\n        \n#         #print ('self.x',self.x)\n        \n#     def __len__(self):\n#         return (len(self.x))\n    \n#     def __getitem__(self, idx):\n#         data = self.x[idx]\n#         label = self.y[idx]\n        \n#         transformed_data = self.transform (data)\n        \n#         return transformed_data, label\n\n# for i,(data,labels) in enumerate(train_data_loader):\n#     print ('data shape',data.size())\n#     img1 = data[0]\n#     print ('img1 shape',img1.size())\n#     print ('img1 ',img1)\n#     break\n    \n    \n# data shape torch.Size([5, 1, 28, 28])\n# img1 shape torch.Size([1, 28, 28])\n# img1  tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.9176, 1.0000,\n#           1.0000, 0.5843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.9176, 1.0000,\n#           1.0000, 0.9059, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.6549, 0.9686, 1.0000,\n#           1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.1961, 0.6039, 1.0000, 1.0000, 0.6431,\n#           0.5255, 0.7216, 0.8667, 0.4745, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],\n#          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.1882, 0.6039, 0.9176, 0.6745, 0.6745, 0.1686,\n#           0.0000, 0.2824, 0.6745, 0.6745, 0.0000, 0.0000, 0.0000, 0.0000,\n#           0.0000, 0.0000, 0.0000, 0.0000],","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.297684Z","iopub.execute_input":"2022-08-17T16:24:42.298308Z","iopub.status.idle":"2022-08-17T16:24:42.314718Z","shell.execute_reply.started":"2022-08-17T16:24:42.298245Z","shell.execute_reply":"2022-08-17T16:24:42.313750Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print ('img1 shape',img1.size())\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nnumpy_image = img1.numpy()\ntranspose_image = numpy_image.transpose(1,2,0)\nprint ('transpose_image shape',transpose_image.shape)\nplt.imshow(transpose_image)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.316298Z","iopub.execute_input":"2022-08-17T16:24:42.316886Z","iopub.status.idle":"2022-08-17T16:24:42.526277Z","shell.execute_reply.started":"2022-08-17T16:24:42.316830Z","shell.execute_reply":"2022-08-17T16:24:42.525330Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"img1 shape torch.Size([1, 28, 28])\ntranspose_image shape (28, 28, 1)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass kan_mnist_net(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.conv1= nn.Conv2d(1,32,5)\n        self.bc1 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2,2)\n        \n        self.conv2= nn.Conv2d(32,64,5)\n        self.bc2 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2)\n        \n        self.fc1 = nn.Linear(64 * 4*4, 1000)\n        self.bc3 = nn.BatchNorm1d(1000)\n        self.drop1 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(1000, 500)\n        self.bc4 = nn.BatchNorm1d(500)\n        self.fc3 = nn.Linear(500, 10)\n    \n    def forward(self,x):\n        conv1_x = F.relu(self.bc1(self.conv1(x)))\n        \n        pool1_x = self.pool1(conv1_x)\n        \n        conv2_x = F.relu(self.bc2(self.conv2(pool1_x)))\n        \n        pool2_x = self.pool2(conv2_x)\n        \n        #print ('pool2_x size', pool2_x.size())\n        \n        flatten_x = pool2_x.view(pool2_x.shape[0],-1)\n        \n        fc1_x = F.relu(self.bc3(self.fc1(flatten_x)))\n        drop1_x = self.drop1 (fc1_x)\n        fc2_x = F.relu(self.bc4(self.fc2(drop1_x)))\n        fc3_x = self.fc3(fc2_x)\n        \n        return fc3_x\n\nmodel = kan_mnist_net()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.527608Z","iopub.execute_input":"2022-08-17T16:24:42.528130Z","iopub.status.idle":"2022-08-17T16:24:42.553205Z","shell.execute_reply.started":"2022-08-17T16:24:42.528097Z","shell.execute_reply":"2022-08-17T16:24:42.552332Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dat_iterator = iter(train_data_loader)\nsample_data = next(dat_iterator)\n\nimage = sample_data[0]\nlabel = sample_data[1]\nprint ('image size',image.size())\n\nprint ('label size',label.size())\nprint ('actual label ',label)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.554475Z","iopub.execute_input":"2022-08-17T16:24:42.555000Z","iopub.status.idle":"2022-08-17T16:24:42.581720Z","shell.execute_reply.started":"2022-08-17T16:24:42.554967Z","shell.execute_reply":"2022-08-17T16:24:42.580831Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"image size torch.Size([100, 1, 28, 28])\nlabel size torch.Size([100])\nactual label  tensor([2, 9, 0, 8, 3, 6, 4, 8, 0, 0, 3, 3, 5, 3, 0, 1, 4, 4, 2, 0, 4, 6, 0, 5,\n        0, 0, 2, 1, 6, 7, 3, 5, 9, 8, 7, 0, 8, 5, 2, 2, 1, 2, 8, 1, 0, 9, 0, 5,\n        3, 0, 8, 5, 2, 2, 3, 4, 8, 6, 4, 0, 6, 5, 6, 3, 9, 5, 8, 8, 5, 0, 8, 7,\n        3, 4, 9, 2, 4, 1, 2, 5, 5, 9, 3, 3, 7, 1, 9, 1, 5, 8, 7, 3, 8, 6, 2, 7,\n        9, 7, 0, 8])\n","output_type":"stream"}]},{"cell_type":"code","source":"output = model(image)\nprint ('output size', output.size())\nprint ('output',output)\nmax_pred = output.argmax(axis=1)\nprint ('max_pred',max_pred)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.583153Z","iopub.execute_input":"2022-08-17T16:24:42.583800Z","iopub.status.idle":"2022-08-17T16:24:42.642323Z","shell.execute_reply.started":"2022-08-17T16:24:42.583765Z","shell.execute_reply":"2022-08-17T16:24:42.641456Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"output size torch.Size([100, 10])\noutput tensor([[-3.6441e-01,  1.7227e-01,  4.6132e-01,  6.7214e-01, -4.8996e-01,\n          7.4778e-02,  3.6423e-02,  7.4930e-02,  1.4266e-01,  3.7051e-01],\n        [-6.5018e-01,  2.4743e-01, -3.7271e-02,  5.0620e-01, -9.2316e-02,\n          5.7231e-01, -4.8772e-01,  1.5743e-01,  1.5746e-01,  5.9566e-01],\n        [-4.2593e-02,  8.9818e-02, -4.3850e-01, -1.0606e-01,  3.1840e-02,\n          4.4898e-02,  4.1197e-01,  1.1268e-01,  1.9261e-01,  5.3510e-01],\n        [-1.6376e-01,  1.3303e-01,  1.1605e-01,  3.9205e-01,  5.8008e-01,\n          6.7612e-01,  5.1384e-01, -2.7579e-01,  2.2735e-01,  4.4136e-02],\n        [ 2.0475e-01, -5.0675e-01, -2.5749e-01, -3.4160e-01,  2.6209e-01,\n          4.6960e-01, -2.3833e-01, -3.0075e-01, -8.3763e-02,  4.0592e-01],\n        [-2.6337e-02, -5.2198e-01,  2.9447e-01,  2.0032e-01, -1.4650e-01,\n         -2.5761e-02,  6.8529e-01,  3.3551e-01,  9.3958e-01,  5.9249e-01],\n        [-4.4584e-01,  1.1083e-01, -4.4410e-01,  2.3976e-01, -1.0652e-01,\n          8.3870e-02,  3.2804e-01, -1.4515e-01,  1.7274e-01,  6.5031e-01],\n        [-1.4584e-01,  3.1947e-01,  6.1896e-01, -2.8099e-01,  5.4711e-01,\n          3.8112e-01,  2.6952e-01, -1.3361e-01,  2.4907e-02, -4.9137e-01],\n        [-4.2525e-01, -3.1155e-01, -4.0837e-01,  2.6711e-01, -1.6631e-01,\n         -2.5925e-02, -9.3159e-01,  1.6600e-01,  4.7575e-01,  5.9128e-01],\n        [-1.5862e-03,  8.4845e-02, -5.5524e-01,  2.6002e-02,  2.6848e-01,\n          1.7487e-01, -3.0269e-01, -4.8982e-01,  3.1271e-01,  3.8881e-01],\n        [-3.0027e-01,  3.2200e-01,  4.5607e-01, -1.6065e-01, -3.9443e-02,\n         -2.3958e-01, -9.4697e-02,  1.5566e-01,  6.5348e-01,  7.9557e-01],\n        [-2.3213e-01, -5.7283e-01,  2.2420e-01, -6.0030e-01,  7.5250e-02,\n         -1.3735e-01,  3.7471e-01, -2.5150e-02,  6.5808e-01,  2.6565e-01],\n        [-6.4264e-01, -1.9515e-02, -1.9289e-01, -4.3792e-01, -1.6469e-02,\n         -1.2630e-01, -4.3300e-01, -1.5870e-01,  4.9330e-01,  4.2868e-01],\n        [-7.0224e-02,  3.8816e-01, -1.6127e-01, -2.8394e-01,  4.3185e-01,\n          4.5052e-01, -4.9598e-01,  5.1772e-01, -2.4879e-01, -1.1354e-01],\n        [-2.0453e-01,  7.9698e-02,  2.6262e-02,  5.8581e-02,  2.2167e-01,\n          3.0983e-01, -2.4957e-01,  1.1776e-01, -2.3355e-01,  9.2838e-01],\n        [-8.7410e-01, -3.7214e-01, -4.8297e-01,  1.9388e-02,  7.1276e-01,\n          2.4697e-01,  1.4210e-01, -1.8285e-01,  4.7129e-01,  1.7032e-01],\n        [-3.0233e-01,  2.3982e-01,  1.5443e-01,  3.0765e-01,  5.8580e-01,\n         -4.6348e-01,  4.3747e-01,  3.3061e-01,  9.1580e-01, -2.2044e-01],\n        [ 1.0792e-01,  2.3583e-01, -5.7687e-01,  4.3442e-01,  5.3841e-01,\n          1.5273e-01, -8.9342e-01, -8.2158e-02,  2.9509e-01,  3.0301e-02],\n        [ 1.0838e-01, -1.9933e-01, -1.2552e-01, -1.7046e-01, -1.4017e-01,\n          3.8794e-01,  4.2483e-01,  1.0936e-01, -1.9250e-01,  1.8511e-01],\n        [-2.1861e-01, -7.5071e-02,  2.4897e-01,  4.4551e-01,  9.9299e-02,\n         -2.6175e-01, -4.2609e-01,  2.4600e-01,  2.4569e-01,  7.5652e-01],\n        [ 3.3477e-01,  5.2650e-01,  8.4185e-02, -6.0687e-02,  8.1097e-01,\n          1.8728e-01,  5.1085e-02,  4.0372e-01,  7.6282e-01, -3.0795e-01],\n        [-3.6333e-01,  6.0992e-02,  9.4580e-01,  4.5544e-01,  2.3126e-02,\n         -3.3338e-01,  3.7176e-01, -2.2401e-01,  6.8804e-01,  5.2376e-02],\n        [-3.4737e-01,  3.5211e-01,  4.4938e-01,  4.8067e-01,  1.4056e-01,\n          5.6579e-02, -8.4915e-02, -2.0602e-01,  2.3991e-01,  4.2343e-01],\n        [-5.4549e-01, -3.5874e-01,  3.5447e-01,  6.3164e-02,  7.7331e-02,\n          4.7862e-01,  2.0446e-01,  1.4162e-01,  1.2839e-01,  2.3823e-01],\n        [-3.7900e-01,  1.9471e-02, -1.4454e-01,  1.3054e-01,  7.8085e-03,\n          3.4420e-01,  2.1564e-01, -4.5505e-01,  4.2165e-01,  3.4992e-01],\n        [-3.1842e-01, -3.5153e-01, -1.8815e-01,  2.7824e-01, -1.5612e-01,\n          3.4210e-01,  2.9313e-01, -2.6315e-01,  6.1009e-01,  8.4366e-01],\n        [-4.7586e-01,  3.0355e-01,  1.3107e-01,  2.9152e-01,  5.2770e-01,\n          4.5134e-01,  1.0992e-01, -1.4753e-01,  2.4189e-01, -3.5647e-02],\n        [-2.0493e-01, -1.5181e-01,  1.6189e-02,  2.4352e-01,  1.2925e+00,\n          3.0803e-01,  3.2309e-02,  2.1617e-01,  6.2458e-01,  4.1116e-01],\n        [-4.9168e-01,  5.8903e-01,  1.0453e-01,  1.5806e-01,  7.2653e-01,\n          5.2950e-01,  6.0936e-01, -4.8500e-01, -8.8221e-02, -2.2813e-01],\n        [ 1.6387e-01,  2.2708e-01,  3.0344e-01,  6.7007e-01,  9.3013e-02,\n          4.2278e-02, -1.3369e-01,  2.3724e-01,  4.4480e-01,  2.6166e-01],\n        [-5.9913e-01,  7.4919e-02,  3.7735e-01, -1.4552e-01,  3.6556e-01,\n         -1.4081e-01, -4.6223e-01,  9.3461e-03,  1.6824e-01, -2.7969e-01],\n        [ 1.4646e-01, -3.8801e-01,  1.7901e-01,  1.5511e-01,  4.9596e-01,\n         -4.6491e-02, -6.9168e-01, -1.8980e-02,  6.5607e-02,  3.1435e-01],\n        [-1.1887e+00, -9.7849e-02,  1.7686e-01,  4.7668e-01,  3.8606e-01,\n          2.1459e-01, -6.1151e-01,  4.0405e-01,  3.1872e-01,  6.4287e-02],\n        [-2.3087e-01,  3.1264e-01, -1.2217e-01, -1.3118e-01,  4.8804e-01,\n          3.9126e-01, -3.6100e-01,  2.5501e-01,  2.5860e-01, -7.1314e-01],\n        [-3.0937e-01, -9.5671e-01, -4.4278e-01,  3.4084e-01,  4.4931e-01,\n         -1.7838e-01,  4.5605e-01,  9.9658e-03,  7.0227e-01,  1.3490e-01],\n        [-4.6918e-01, -1.5800e-01,  5.0910e-02,  7.5659e-02,  3.1386e-01,\n         -3.4189e-01,  2.4037e-01,  7.2926e-02,  4.5921e-01,  1.4654e-02],\n        [-3.6774e-01,  6.2168e-02,  1.6287e-01, -4.7179e-02, -2.3940e-01,\n          3.6268e-01, -3.4880e-01, -2.5466e-01,  2.2519e-01,  4.1394e-03],\n        [-4.0130e-01, -5.3353e-01, -4.7790e-01,  1.9579e-01,  9.8055e-02,\n          3.4395e-01, -3.1693e-01,  4.2218e-02,  2.3008e-01,  1.2456e-02],\n        [-4.5746e-01, -5.7486e-01,  9.6065e-02,  3.3974e-01,  2.2602e-01,\n         -5.8787e-01, -4.2548e-01, -9.7482e-02,  9.1911e-01, -1.1675e-01],\n        [-2.4151e-01, -2.0267e-01,  3.1074e-02,  4.5608e-01,  2.5842e-01,\n          7.3293e-02,  1.4598e-01,  2.3628e-01, -4.1883e-01,  5.6067e-02],\n        [ 1.7681e-01,  3.8476e-02,  8.7292e-02, -4.7757e-01,  2.1315e-02,\n          3.4114e-01,  5.1435e-02,  8.4117e-01,  4.1163e-01,  5.3558e-01],\n        [-1.4867e-01,  2.9987e-01,  3.6573e-02, -4.4776e-01, -1.8462e-01,\n         -6.4258e-01,  6.8042e-01, -2.0859e-01,  3.2243e-01,  2.4939e-01],\n        [ 1.4205e-01,  1.6240e-02,  7.2688e-01,  5.9146e-02, -1.6118e-01,\n          4.3164e-01, -7.6495e-02, -2.7253e-01,  3.7518e-01,  1.3219e-01],\n        [-1.7229e-01, -2.6844e-01,  3.1673e-01, -1.7806e-01,  5.6281e-01,\n         -8.9289e-02,  1.0655e-01, -2.0818e-01,  6.2480e-01,  6.3324e-01],\n        [-1.5482e-01, -3.8812e-01, -2.5541e-01,  5.2211e-01,  6.2370e-02,\n         -4.2681e-02, -2.1052e-01,  4.0318e-01,  1.2987e-01,  3.0458e-01],\n        [-1.0750e-01,  3.8618e-01, -5.7138e-01,  3.8825e-01,  1.0044e-01,\n          6.6401e-01,  3.3888e-01, -2.6317e-02,  1.7399e-02, -1.3822e-01],\n        [-2.2353e-02, -2.1835e-01,  4.9563e-01, -1.6761e-01,  1.4915e-01,\n          4.7814e-01, -2.2091e-02, -6.4714e-02,  1.5624e-01,  6.1544e-01],\n        [ 7.4280e-02, -2.0174e-02, -1.0861e-01,  6.0504e-02, -3.7008e-01,\n          1.4217e-01, -3.7822e-01, -8.9186e-02,  2.0989e-01,  4.0337e-01],\n        [-3.1239e-01,  2.3784e-01, -1.7712e-01, -9.4857e-02,  1.7179e-01,\n          2.3758e-02, -3.3592e-02,  6.5404e-01, -9.8150e-02,  3.9473e-01],\n        [-2.5946e-01, -3.3526e-01, -7.4983e-01,  6.6973e-03,  2.1213e-01,\n         -3.0382e-01,  6.3817e-02, -1.4272e-01,  6.7603e-01, -2.1645e-03],\n        [-3.0299e-02,  1.6293e-01,  3.8141e-01,  1.7805e-02,  1.1210e-01,\n          3.8030e-02,  1.7566e-01, -1.1576e-01,  1.9326e-01, -9.3774e-02],\n        [-1.6580e-01, -2.6454e-01,  3.8339e-01, -3.4520e-01,  1.5995e-01,\n         -6.2699e-02, -3.0545e-01, -9.5976e-02,  3.1119e-01, -4.3243e-01],\n        [-3.7747e-01, -9.6149e-02, -1.5178e-01,  2.6407e-01, -2.1447e-02,\n         -3.5444e-02,  2.1870e-02, -6.1702e-01,  5.9832e-03, -4.6973e-02],\n        [-3.4355e-01,  1.7095e-01, -4.1887e-01,  7.4270e-01,  4.0439e-01,\n          5.3879e-02, -2.6875e-01, -1.6995e-01,  3.5598e-01, -1.2383e-03],\n        [ 3.2238e-01, -2.2776e-01, -9.3726e-02,  2.9570e-01,  2.3937e-01,\n         -1.8501e-01, -7.9649e-02, -5.0506e-01,  6.9407e-01,  3.0183e-01],\n        [-2.1046e-01, -4.7052e-01,  9.6621e-02,  1.1449e-01,  3.4055e-01,\n          1.2812e-01, -1.0395e-01,  1.3377e-01, -4.3882e-02, -3.4876e-01],\n        [-3.6548e-02,  4.2031e-01,  6.8367e-02, -2.3431e-02, -3.0100e-01,\n          6.8924e-01, -7.6051e-01,  1.0996e-02,  7.9683e-01, -2.2585e-02],\n        [-5.3538e-01, -1.8044e-01,  5.8332e-01,  2.4483e-01,  9.2430e-02,\n          1.3758e-02, -5.5069e-01,  5.1256e-01,  7.7066e-01,  5.9983e-01],\n        [-5.4289e-01, -3.4482e-01,  1.1695e-01, -3.1416e-01,  1.0334e-01,\n          1.6796e-01, -6.6193e-02, -1.0620e-01,  1.7075e-01,  1.0487e-01],\n        [ 4.5633e-01,  2.9016e-01,  2.6490e-01, -1.1264e-01,  2.9364e-01,\n          6.3991e-01,  2.3600e-01, -6.0511e-02,  1.6213e-01,  4.6072e-01],\n        [-5.2465e-01, -2.6398e-01, -6.8240e-02,  3.5493e-02, -5.4257e-01,\n          4.4101e-01, -7.5118e-02, -3.7378e-02,  2.2896e-02,  1.5581e-02],\n        [-2.1716e-01, -1.1195e-01, -4.0399e-01, -1.7863e-01,  4.8818e-01,\n         -4.0516e-01, -3.4525e-01,  2.8939e-01,  2.5909e-01,  1.4434e-01],\n        [ 7.6312e-01,  5.1232e-02,  7.2904e-02, -4.0409e-01,  3.4872e-02,\n          5.9752e-01,  1.0596e+00,  7.7972e-02, -1.5965e-01, -2.9578e-01],\n        [ 2.9645e-02, -1.7058e-01, -3.5865e-01,  2.9874e-01, -1.7225e-01,\n          2.6244e-01,  2.2445e-01, -6.4889e-01,  1.3947e-01,  2.3021e-01],\n        [ 4.2161e-01,  6.5465e-01, -3.8682e-01,  2.0537e-01, -1.2735e-02,\n          1.8555e-02, -1.6687e-02,  4.3735e-01, -4.5993e-01, -3.2466e-02],\n        [ 7.1388e-01, -4.8028e-01,  1.5953e-02, -1.3861e-01, -2.7515e-02,\n          1.7981e-01,  1.1946e-01,  5.8344e-02,  5.3829e-01,  3.5056e-01],\n        [ 2.9642e-01, -4.6165e-01,  1.0334e+00, -2.5600e-01,  1.9838e-01,\n          6.0503e-01, -5.8807e-01, -2.4113e-01,  1.4154e+00,  7.6419e-01],\n        [-3.7446e-01,  8.8690e-02,  3.0232e-01,  2.9731e-01, -7.8462e-01,\n          1.7843e-01,  7.9349e-01, -4.1617e-01,  1.8167e-01, -3.8441e-02],\n        [-4.3443e-01, -6.0431e-01,  1.5718e-01,  6.1409e-01,  1.0585e+00,\n          2.6849e-01, -2.1990e-01, -1.9602e-01,  9.7268e-01,  3.3135e-01],\n        [-2.9595e-01, -3.8241e-01,  1.9455e-01, -7.7559e-03,  6.5706e-01,\n          1.4317e-02, -5.4551e-01,  5.8462e-01,  4.6963e-01,  6.0843e-01],\n        [-6.4132e-01, -1.0877e-01,  5.0782e-01, -1.3383e-01,  2.8142e-01,\n         -2.5661e-02,  8.4000e-03,  4.6352e-01,  6.4742e-01,  7.0855e-01],\n        [ 8.4423e-02,  8.2044e-01, -1.4165e-01,  5.4419e-02,  1.6159e-01,\n          6.6178e-02,  1.1476e+00, -1.4330e-01, -6.0396e-02, -9.9849e-02],\n        [-4.2494e-01, -8.9670e-04,  4.9363e-01, -2.5436e-01,  3.4312e-03,\n         -1.2652e-02, -1.8642e-02,  3.3988e-02,  1.6202e-01, -2.2202e-02],\n        [-2.7686e-01, -7.2835e-02,  3.3346e-01, -8.3133e-01, -9.4732e-01,\n          6.3552e-01, -6.2087e-01,  4.4007e-02,  4.9013e-01,  5.0530e-01],\n        [-2.8148e-01,  2.0595e-01, -4.1652e-02,  5.5739e-02,  5.7697e-01,\n          3.9952e-01, -3.5392e-01,  4.4943e-01,  7.3550e-02, -4.2020e-02],\n        [ 5.1040e-01,  6.6432e-02, -2.1548e-01,  8.6601e-02, -8.8785e-01,\n         -3.1368e-01,  4.9588e-01, -1.1158e-01,  1.4370e-01,  5.0664e-01],\n        [-1.8506e-01,  4.6768e-01, -3.5770e-01, -2.9600e-01, -3.9395e-01,\n          4.9960e-01, -2.4194e-01,  7.0876e-01,  2.1342e-01, -1.0576e-01],\n        [-8.1179e-02,  3.8985e-01, -2.2224e-01,  4.6845e-02,  7.9380e-02,\n         -1.5773e-01, -4.3500e-01,  5.0934e-02,  6.3646e-01,  5.5028e-01],\n        [ 2.4800e-01,  7.4253e-02,  6.3731e-01,  3.2760e-01,  3.5352e-01,\n          9.5803e-01, -1.6523e-01,  2.9990e-01,  4.5678e-01, -1.8616e-01],\n        [-7.8672e-02,  3.2301e-01, -1.7737e-01,  1.2781e-01, -1.2372e-01,\n          2.3227e-01,  7.2328e-01,  6.7224e-01,  4.2045e-01, -1.1956e-01],\n        [-3.2794e-01, -1.1395e-01,  1.1020e-01,  9.3348e-02,  2.0929e-01,\n          1.3368e-01, -1.8681e-01,  3.7743e-01,  3.0988e-01,  1.2965e-01],\n        [-2.0489e-01, -2.6482e-01,  4.4898e-01, -1.5873e-01,  1.1319e+00,\n          1.2302e-01, -5.5497e-01,  6.0487e-01, -3.0404e-01,  4.0714e-02],\n        [-3.8551e-01, -3.5375e-01,  1.9050e-01,  1.4820e-01, -7.4580e-02,\n          1.3972e-01, -3.5439e-02, -3.8939e-01,  9.5840e-02,  3.6007e-01],\n        [ 3.3706e-01, -1.5121e-01, -2.1960e-01,  2.1424e-01,  9.7376e-02,\n         -5.5997e-02, -4.3147e-01,  1.0287e+00,  1.4344e-01, -2.0337e-01],\n        [-2.7064e-01, -3.8961e-02,  2.7087e-01, -4.3382e-01, -1.8434e-02,\n         -2.8368e-01, -6.8100e-01,  1.8579e-01,  4.3383e-02,  3.0200e-02],\n        [ 8.4150e-02, -1.2033e-02,  5.1809e-01, -1.5462e-01,  2.8456e-02,\n          3.3657e-02,  5.2665e-02,  1.4738e-01, -4.5179e-01,  1.2388e+00],\n        [-3.4974e-01, -9.0983e-02,  3.1250e-02,  7.6008e-01,  1.7280e-01,\n          1.7480e-01, -9.2834e-02, -1.2693e-01,  2.2140e-01, -2.1503e-01],\n        [-1.6562e-01, -2.2247e-01,  5.3904e-02,  3.4133e-01,  3.4982e-02,\n          5.3824e-02, -5.8657e-01,  1.6759e-01,  1.8249e-01,  7.3122e-01],\n        [ 6.6908e-02,  7.9875e-02,  2.1093e-01,  4.9743e-01,  2.8781e-01,\n          3.6677e-02, -3.9367e-01,  3.2190e-01,  3.3894e-01,  5.3786e-01],\n        [-6.2350e-01, -3.4210e-02, -1.3076e-01,  3.8190e-02, -3.9601e-01,\n          5.1673e-01, -6.6126e-01, -1.4506e-01,  8.4706e-01,  8.3915e-01],\n        [ 2.2852e-01,  6.6049e-02,  2.5881e-01,  8.1492e-01,  1.5099e-01,\n          1.0352e-02,  7.2067e-01,  8.5762e-02,  1.6715e-01,  6.2501e-01],\n        [ 5.2098e-01,  1.9144e-01, -1.2252e-01,  2.2549e-01,  2.7662e-01,\n          1.1759e-01,  3.3986e-01, -1.0600e-01,  3.1312e-02, -3.0761e-01],\n        [-9.2290e-01,  1.5165e-01,  1.0551e-01,  5.1275e-02, -2.6415e-01,\n          6.5637e-01, -7.1243e-02,  4.3878e-01, -2.7367e-01,  3.8187e-01],\n        [-2.2143e-01,  3.2817e-01,  4.4011e-01,  4.8354e-01,  1.5542e-01,\n          7.6163e-02,  2.8094e-01,  2.8029e-01,  4.3413e-01,  4.8915e-01],\n        [ 2.4388e-01, -7.0179e-03, -2.1097e-01,  2.0652e-01,  9.1464e-01,\n         -3.4919e-02, -9.3228e-02, -3.5007e-01,  3.7533e-01,  5.1317e-01],\n        [ 3.9158e-01, -4.2065e-02,  3.7364e-01,  4.2914e-01,  5.8887e-01,\n          1.1656e-01,  7.7509e-01, -6.9179e-01, -2.7362e-01, -1.8810e-01],\n        [ 1.3523e-01,  2.8300e-01, -2.3845e-01,  7.2042e-02,  7.5184e-02,\n         -4.0713e-03,  3.1834e-01,  3.8156e-01,  7.3070e-01, -2.1882e-01],\n        [-4.3411e-01,  3.1251e-01, -2.1400e-01, -7.7066e-01,  6.1108e-02,\n          3.5908e-02,  7.4018e-01, -1.3959e-01,  2.5723e-01, -6.1783e-02],\n        [-3.0588e-02,  1.7580e-01, -4.4361e-01,  8.3180e-03,  4.9391e-01,\n          2.6406e-01,  3.8730e-01,  2.6144e-02,  1.4537e-01,  5.9954e-01],\n        [-3.1023e-02, -1.7526e-01, -1.2897e-01,  9.4840e-02,  3.3590e-01,\n          2.0276e-01,  5.4265e-01,  3.0833e-02,  5.5265e-01,  2.4386e-01]],\n       grad_fn=<AddmmBackward0>)\nmax_pred tensor([3, 9, 9, 5, 5, 8, 9, 2, 9, 9, 9, 8, 8, 7, 9, 4, 8, 4, 6, 9, 4, 2, 3, 5,\n        8, 9, 4, 4, 4, 3, 2, 4, 3, 4, 8, 8, 5, 5, 8, 3, 7, 6, 2, 9, 3, 5, 9, 9,\n        7, 8, 2, 2, 3, 3, 8, 4, 8, 8, 8, 5, 5, 4, 6, 3, 1, 0, 8, 6, 4, 4, 9, 6,\n        2, 5, 4, 0, 7, 8, 5, 6, 7, 4, 9, 7, 2, 9, 3, 9, 9, 8, 3, 0, 5, 9, 4, 6,\n        8, 6, 9, 8])\n","output_type":"stream"}]},{"cell_type":"code","source":"model.parameters","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.643847Z","iopub.execute_input":"2022-08-17T16:24:42.644492Z","iopub.status.idle":"2022-08-17T16:24:42.650573Z","shell.execute_reply.started":"2022-08-17T16:24:42.644455Z","shell.execute_reply":"2022-08-17T16:24:42.649800Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<bound method Module.parameters of kan_mnist_net(\n  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n  (bc1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n  (bc2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=1024, out_features=1000, bias=True)\n  (bc3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (drop1): Dropout(p=0.5, inplace=False)\n  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n  (bc4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc3): Linear(in_features=500, out_features=10, bias=True)\n)>"},"metadata":{}}]},{"cell_type":"code","source":"import time\nstart = time.time()\nprint ('start',start)\n\n\nmodel = kan_mnist_net()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters(),lr=0.001)\n#using params=model.parameters() is very important\n#below did not cause convergence\n#optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n\nmodel.train()\n\nepochs = 10\n\nfor e in range(epochs):\n    \n    running_loss = 0\n    cnt = 0\n    print ('new epoch')\n    for i, data in enumerate(train_data_loader):\n        cnt+=1 \n        \n        image =data[0]\n        label = data[1]\n          \n        \n        #image = image.type(torch.FloatTensor)\n        \n        output = model(image)\n        \n        optimizer.zero_grad()\n        \n        loss = criterion(output,label)\n    \n        loss.backward()\n        \n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        if cnt%100 == 99:\n            print (f\"epoch {e} , i {i}, running_loss {running_loss}\")\n            running_loss = 0\n            \nend = time.time()\nprint ('end',end)\nprint('time taken',end - start)\nprint('time taken minutes',(end - start)/60)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:24:42.652277Z","iopub.execute_input":"2022-08-17T16:24:42.652942Z","iopub.status.idle":"2022-08-17T16:32:44.403993Z","shell.execute_reply.started":"2022-08-17T16:24:42.652883Z","shell.execute_reply":"2022-08-17T16:32:44.401990Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"start 1660753482.659891\nnew epoch\nepoch 0 , i 98, running_loss 18.317671174183488\nepoch 0 , i 198, running_loss 5.318625368177891\nepoch 0 , i 298, running_loss 5.501658413559198\nepoch 0 , i 398, running_loss 4.230362693313509\nepoch 0 , i 498, running_loss 3.860845262883231\nepoch 0 , i 598, running_loss 3.930118155782111\nnew epoch\nepoch 1 , i 98, running_loss 2.6614626785740256\nepoch 1 , i 198, running_loss 2.400944226188585\nepoch 1 , i 298, running_loss 2.3059032590826973\nepoch 1 , i 398, running_loss 2.828382037812844\nepoch 1 , i 498, running_loss 2.92184019763954\nepoch 1 , i 598, running_loss 2.6113224792061374\nnew epoch\nepoch 2 , i 98, running_loss 1.7389130536466837\nepoch 2 , i 198, running_loss 2.069066682102857\nepoch 2 , i 298, running_loss 1.8990365218487568\nepoch 2 , i 398, running_loss 1.8313716683769599\nepoch 2 , i 498, running_loss 2.1180490744882263\nepoch 2 , i 598, running_loss 1.6691223699017428\nnew epoch\nepoch 3 , i 98, running_loss 1.0814889403409325\nepoch 3 , i 198, running_loss 1.1825340504292399\nepoch 3 , i 298, running_loss 1.540278282482177\nepoch 3 , i 398, running_loss 1.5575590962835122\nepoch 3 , i 498, running_loss 2.368561062205117\nepoch 3 , i 598, running_loss 1.8101478011521976\nnew epoch\nepoch 4 , i 98, running_loss 1.308642346470151\nepoch 4 , i 198, running_loss 1.3413088209345005\nepoch 4 , i 298, running_loss 1.484497627359815\nepoch 4 , i 398, running_loss 1.318514680082444\nepoch 4 , i 498, running_loss 1.444854550092714\nepoch 4 , i 598, running_loss 1.2951891302654985\nnew epoch\nepoch 5 , i 98, running_loss 1.042700225545559\nepoch 5 , i 198, running_loss 0.7152413430230808\nepoch 5 , i 298, running_loss 0.9142701570090139\nepoch 5 , i 398, running_loss 1.325232710572891\nepoch 5 , i 498, running_loss 1.4298681863292586\nepoch 5 , i 598, running_loss 1.3264192106726114\nnew epoch\nepoch 6 , i 98, running_loss 1.0818247799179517\nepoch 6 , i 198, running_loss 1.0803416823982843\nepoch 6 , i 298, running_loss 1.071763560139516\nepoch 6 , i 398, running_loss 1.3603453477553558\nepoch 6 , i 498, running_loss 0.9244488922340679\nepoch 6 , i 598, running_loss 1.0019529194287315\nnew epoch\nepoch 7 , i 98, running_loss 0.6964044809137704\nepoch 7 , i 198, running_loss 0.736239438130724\nepoch 7 , i 298, running_loss 0.9650633728451794\nepoch 7 , i 398, running_loss 0.8073353759245947\nepoch 7 , i 498, running_loss 0.8750368274486391\nepoch 7 , i 598, running_loss 0.9651719556131866\nnew epoch\nepoch 8 , i 98, running_loss 0.670853896837798\nepoch 8 , i 198, running_loss 0.6166667455981951\nepoch 8 , i 298, running_loss 1.068528117146343\nepoch 8 , i 398, running_loss 0.9298803187266458\nepoch 8 , i 498, running_loss 0.8876483962449129\nepoch 8 , i 598, running_loss 1.0476361632463522\nnew epoch\nepoch 9 , i 98, running_loss 1.0247240745520685\nepoch 9 , i 198, running_loss 0.7657608423178317\nepoch 9 , i 298, running_loss 0.8179127704752318\nepoch 9 , i 398, running_loss 0.6052257819064835\nepoch 9 , i 498, running_loss 0.5282608226843877\nepoch 9 , i 598, running_loss 0.8320718756294809\nend 1660753964.3973234\ntime taken 481.7374324798584\ntime taken minutes 8.02895720799764\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction on test dataset","metadata":{}},{"cell_type":"code","source":"kan_test_data = kan_dataset('/kaggle/input/Kannada-MNIST/test.csv',transform=my_tranforms,test_data=1)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:44.406699Z","iopub.execute_input":"2022-08-17T16:32:44.407892Z","iopub.status.idle":"2022-08-17T16:32:44.865978Z","shell.execute_reply.started":"2022-08-17T16:32:44.407835Z","shell.execute_reply":"2022-08-17T16:32:44.864641Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nbatch_size= 100\ntest_data_loader = DataLoader(kan_test_data,batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:44.867927Z","iopub.execute_input":"2022-08-17T16:32:44.868426Z","iopub.status.idle":"2022-08-17T16:32:44.874044Z","shell.execute_reply.started":"2022-08-17T16:32:44.868379Z","shell.execute_reply":"2022-08-17T16:32:44.873171Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"for i,data in enumerate(test_data_loader):\n    print ('data shape',data.size())\n    img1 = data[0]\n    print ('img1 shape',img1.size())\n    #print ('img1 ',img1)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:44.875505Z","iopub.execute_input":"2022-08-17T16:32:44.876084Z","iopub.status.idle":"2022-08-17T16:32:44.902279Z","shell.execute_reply.started":"2022-08-17T16:32:44.876049Z","shell.execute_reply":"2022-08-17T16:32:44.901054Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"data shape torch.Size([100, 1, 28, 28])\nimg1 shape torch.Size([1, 28, 28])\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions_tensor = torch.IntTensor()\n\nwith torch.no_grad():\n    \n    for i,data in enumerate(test_data_loader):\n        \n        image= data\n        test_out = model(image)\n        max_pred = test_out.argmax(axis=1)\n        \n              \n        predictions_tensor = torch.cat((predictions_tensor,max_pred))    \n\nprint ('predictions_tensor size',predictions_tensor.size())\n#print ('predictions_tensor ',predictions_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:44.904130Z","iopub.execute_input":"2022-08-17T16:32:44.905116Z","iopub.status.idle":"2022-08-17T16:32:46.498883Z","shell.execute_reply.started":"2022-08-17T16:32:44.905074Z","shell.execute_reply":"2022-08-17T16:32:46.497236Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"predictions_tensor size torch.Size([5000])\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\nresult_df=test_df[['id']]\n\nresult_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:46.500451Z","iopub.execute_input":"2022-08-17T16:32:46.501074Z","iopub.status.idle":"2022-08-17T16:32:46.814830Z","shell.execute_reply.started":"2022-08-17T16:32:46.501026Z","shell.execute_reply":"2022-08-17T16:32:46.813575Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"   id\n0   0\n1   1\n2   2\n3   3\n4   4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"result_df['label'] = predictions_tensor.numpy()\nresult_df","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:46.816453Z","iopub.execute_input":"2022-08-17T16:32:46.816927Z","iopub.status.idle":"2022-08-17T16:32:46.837470Z","shell.execute_reply.started":"2022-08-17T16:32:46.816869Z","shell.execute_reply":"2022-08-17T16:32:46.836119Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"        id  label\n0        0      3\n1        1      0\n2        2      2\n3        3      6\n4        4      7\n...    ...    ...\n4995  4995      1\n4996  4996      1\n4997  4997      1\n4998  4998      6\n4999  4999      3\n\n[5000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>4995</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>4996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>4997</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>4998</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>4999</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows  2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"result_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:46.839725Z","iopub.execute_input":"2022-08-17T16:32:46.840125Z","iopub.status.idle":"2022-08-17T16:32:46.855745Z","shell.execute_reply.started":"2022-08-17T16:32:46.840091Z","shell.execute_reply":"2022-08-17T16:32:46.854826Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#we will use train dataset itself for time being\n# model.eval()\n\n# with torch.no_grad():\n#     all_train_preds = []\n#     cnt = 0 \n#     for i, data in enumerate(val_data_loader):\n#         cnt+=1 \n        \n#         image =data[0]\n#         label = data[1]\n                  \n#         train_output = model(image) \n#         max_pred = train_output.argmax(axis=1)\n        \n#         print ('label size',label.size())\n#         print ('max_pred size',max_pred.size())\n        \n#         print ('label ',label)\n#         print ('max_pred ',max_pred)\n        \n#         mask = label == max_pred\n        \n#         print ('mask',mask)\n        \n#         matching_values = max_pred[mask]\n        \n#         print ('matching_values size',matching_values.size())\n        \n#         print ('matching_values',matching_values)\n            \n        \n#         break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:32:46.857178Z","iopub.execute_input":"2022-08-17T16:32:46.858271Z","iopub.status.idle":"2022-08-17T16:32:46.864716Z","shell.execute_reply.started":"2022-08-17T16:32:46.858224Z","shell.execute_reply":"2022-08-17T16:32:46.863333Z"},"trusted":true},"execution_count":53,"outputs":[]}]}